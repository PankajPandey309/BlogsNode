(['Natural language processing', 'Natural language', 'Outline of natural language processing', 'History of natural language processing', 'Natural-language understanding', 'Natural Language Toolkit', 'Natural-language user interface', 'Language model', 'Natural-language programming', 'List of artificial intelligence projects'], None)
(['Machine learning', 'Quantum machine learning', 'Active learning (machine learning)', 'List of datasets for machine-learning research', 'Boosting (machine learning)', 'Transformer (machine learning model)', 'Hyperparameter (machine learning)', 'Support-vector machine', 'Deep learning', 'Automated machine learning'], 'machine ;earning')
(['Quantum machine learning', 'Machine learning in physics', 'Quantum computing', 'Wave interference', 'Xanadu Quantum Technologies', 'List of datasets for machine-learning research', 'Quantum neural network', 'Quantum technology', 'Cambridge Quantum Computing', 'List of companies involved in quantum computing or communication'], None)
(['Artificial intelligence', 'Artificial general intelligence', 'A.I. Artificial Intelligence', 'Swarm intelligence', 'Philosophy of artificial intelligence', 'Applications of artificial intelligence', 'History of artificial intelligence', 'Artificial intelligence in video games', 'Ethics of artificial intelligence', 'Existential risk from artificial general intelligence'], None)
(['Data science', 'Master in Data Science', 'Data type', 'Open science data', 'Data analysis', 'Data', 'Big data', 'Committee on Data for Science and Technology', 'Data structure', 'Computer science'], None)
(['Master in Data Science', 'Master of Science in Information Technology', "List of master's degrees", 'Master of Library and Information Science', 'Master of Science in Information Systems', 'NASA Space Science Data Coordinated Archive', 'Hertie School', 'Master of Science in Business Analytics', "List of master's degrees in North America", 'Political science'], None)
(['Bank of America', 'Bank of America Private Bank', 'Bank of America Tower (Manhattan)', 'Bank of America Stadium', 'American Express', 'Bank of America Home Loans', 'Bank of America Corporate Center', 'Bank of North America', 'Bank of America Plaza (Atlanta)', 'Bank of America Tower'], 'band of america')
(['Visa Inc.', 'Visa', '3-D Secure', 'Alfred F. Kelly Jr.', 'Mastercard', 'Visa Debit', 'List of most valuable brands', 'Verisk Analytics', 'Plus (interbank network)', 'Charles Scharf'], 'visa bin')
(['European Central Bank', 'Central bank', 'President of the European Central Bank', 'European System of Central Banks', 'Seat of the European Central Bank', 'Central and Eastern Europe', 'Central banks and currencies of Europe', 'Central Bank of Ireland', 'Central bank digital currency', 'List of central banks'], None)
(['Bank', 'BANK (art collective)', 'Commercial bank', 'West Bank', 'World Bank', 'Investment banking', 'State Bank of India', 'Central Bank of Russia', 'Saudi National Bank (bank)', 'List of banks in India'], 'band')
/Users/pankajpandey/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 389 of the file /Users/pankajpandey/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  lis = BeautifulSoup(html).find_all('li')
(['Tennis', 'Table tennis', 'ATP Tour Masters 1000', 'History of tennis', 'Grand Slam (tennis)', "Open Era tennis records – Men's singles", 'Novak Djokovic', 'ATP Tour 500', 'ATP Tour 250', 'Dubai Tennis Championships'], 'tenic')
(['Football', 'College football', 'Football player', 'Australian rules football', 'Association football', 'List of English football champions', 'England national football team', 'Russia national football team', 'Defender (association football)', 'Nebraska Cornhuskers football'], None)
(['Basketball', 'Basketball positions', 'History of basketball', 'College basketball', "North Carolina Tar Heels men's basketball", "Women's basketball", "Michigan Wolverines men's basketball", 'FIBA Basketball World Cup', "Wisconsin Badgers men's basketball", 'Boston Basketball Partners'], 'baseball')
(['Swimming', 'Swimming (sport)', 'Swimming pool', 'Nude swimming', 'Synchronized swimming', 'FINA World Aquatics Championships', 'Freestyle swimming', 'Swimming at the 2020 Summer Olympics', 'Swimming at the Summer Olympics', 'Azure Swimming Pool'], None)
(['Tennis', 'Table tennis', 'ATP Tour Masters 1000', 'History of tennis', 'Grand Slam (tennis)', "Open Era tennis records – Men's singles", 'Novak Djokovic', 'ATP Tour 500', 'ATP Tour 250', 'Dubai Tennis Championships'], 'tenic')
["The following is a list of current and past, non-classified notable artificial intelligence projects.\n\n\n== Specialized projects ==\n\n\n=== Brain-inspired ===\nBlue Brain Project, an attempt to create a synthetic brain by reverse-engineering the mammalian brain down to the molecular level.\nGoogle Brain A deep learning project part of Google X attempting to have intelligence similar or equal to human-level.\nHuman Brain Project\nNuPIC, an open source implementation by Numenta of its cortical learning algorithm.\n\n\n=== Cognitive architectures ===\n\n4CAPS, developed at Carnegie Mellon University under Marcel A. Just\nACT-R, developed at Carnegie Mellon University under John R. Anderson.\nAIXI, Universal Artificial Intelligence developed by Marcus Hutter at IDSIA and ANU.\nCALO, a DARPA-funded, 25-institution effort to integrate many artificial intelligence approaches (natural language processing, speech recognition, machine vision, probabilistic logic, planning, reasoning, many forms of machine learning) into an AI assistant that learns to help manage your office environment.\nCHREST, developed under Fernand Gobet at Brunel University and Peter C. Lane at the University of Hertfordshire.\nCLARION, developed under Ron Sun at Rensselaer Polytechnic Institute and University of Missouri.\nCoJACK, an ACT-R inspired extension to the JACK multi-agent system that adds a cognitive architecture to the agents for eliciting more realistic (human-like) behaviors in virtual environments.\nCopycat, by Douglas Hofstadter and Melanie Mitchell at the Indiana University.\nDUAL, developed at the New Bulgarian University under Boicho Kokinov.\nFORR developed by Susan L. Epstein at The City University of New York.\nIDA and LIDA, implementing Global Workspace Theory, developed under Stan Franklin at the University of Memphis.\nOpenCog Prime, developed using the OpenCog Framework.\nProcedural Reasoning System (PRS), developed by Michael Georgeff and Amy L. Lansky at SRI International.\nPsi-Theory developed under Dietrich Dörner at the Otto-Friedrich University in Bamberg, Germany.\nR-CAST, developed at the Pennsylvania State University.\nSoar, developed under Allen Newell and John Laird at Carnegie Mellon University and the University of Michigan.\nSociety of mind and its successor the Emotion machine proposed by Marvin Minsky.\nSubsumption architectures, developed e.g. by Rodney Brooks (though it could be argued whether they are cognitive).\n\n\n=== Games ===\nAlphaGo, software developed by Google that plays the Chinese board game Go.\nChinook, a computer program that plays English draughts; the first to win the world champion title in the competition against humans.\nDeep Blue, a chess-playing computer developed by IBM which beat Garry Kasparov in 1997.\nFreeHAL, a self-learning conversation simulator (chatterbot) which uses semantic nets to organize its knowledge to imitate a very close human behavior within conversations.\nHalite, an artificial intelligence programming competition created by Two Sigma.\nLibratus, a poker AI that beat world-class poker players in 2017, intended to be generalisable to other applications.\nQuick, Draw!, an online game developed by Google that challenges players to draw a picture of an object or idea and then uses a neural network to guess what the drawing is.\nStockfish AI, an open source chess engine currently ranked the highest in many computer chess rankings.\nTD-Gammon, a program that learned to play world-class backgammon partly by playing against itself (temporal difference learning with neural networks).\n\n\n=== Internet activism ===\nSerenata de Amor, project for the analysis of public expenditures and detect discrepancies.\n\n\n=== Knowledge and reasoning ===\nBraina, an intelligent personal assistant application with a voice interface for Windows OS.\nCyc, an attempt to assemble an ontology and database of everyday knowledge, enabling human-like reasoning.\nEurisko, a language by Douglas Lenat for solving problems which consists of heuristics, including some for how to use and change its heuristics.\nGoogle Now, an intelligent personal assistant with a voice interface in Google's Android and Apple Inc.'s iOS, as well as Google Chrome web browser on personal computers.\nHolmes a new AI created by Wipro.\nMicrosoft Cortana, an intelligent personal assistant with a voice interface in Microsoft's various Windows 10 editions.\nMycin, an early medical expert system.\nOpen Mind Common Sense, a project based at the MIT Media Lab to build a large common sense knowledge base from online contributions.\nP.A.N., a publicly available text analyzer.\nSiri, an intelligent personal assistant and knowledge navigator with a voice-interface in Apple Inc.'s iOS and macOS.\nSNePS, simultaneously a logic-based, frame-based, and network-based knowledge representation, reasoning, and acting system.\nViv (software), a new AI by the creators of Siri.\nWolfram Alpha, an online service that answers queries by computing the answer from structured data.\n\n\n=== Motion and manipulation ===\nAIBO, the robot pet for the home, grew out of Sony's Computer Science Laboratory (CSL).\nCog, a robot developed by MIT to study theories of cognitive science and artificial intelligence, now discontinued.\n\n\n=== Music ===\nMelomics, a bioinspired technology for music composition and synthesization of music, where computers develop their own style, rather than mimic musicians.\n\n\n=== Natural language processing ===\nAIML, an XML dialect for creating natural language software agents.\nApache Lucene, a high-performance, full-featured text search engine library written entirely in Java.\nApache OpenNLP, a machine learning based toolkit for the processing of natural language text. It supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking and parsing.\nArtificial Linguistic Internet Computer Entity (A.L.I.C.E.), an award-winning natural language processing chatterbot.\nCleverbot, successor to Jabberwacky, now with 170m lines of conversation, Deep Context, fuzziness and parallel processing. Cleverbot learns from around 2 million user interactions per month.\nELIZA, a famous 1966 computer program by Joseph Weizenbaum, which parodied person-centered therapy.\nGPT-3, a 2020 language model developed by OpenAI that can produce text difficult to distinguish from that written by a human.\nJabberwacky, a chatbot by Rollo Carpenter, aiming to simulate natural human chat.\nMycroft, a free and open-source intelligent personal assistant that uses a natural language user interface.\nPARRY, another early chatterbot, written in 1972 by Kenneth Colby, attempting to simulate a paranoid schizophrenic.\nSHRDLU, an early natural language processing computer program developed by Terry Winograd at MIT from 1968 to 1970.\nSYSTRAN, a machine translation technology by the company of the same name, used by Yahoo!, AltaVista and Google, among others.\nASR-automated speech recognization System.\n\n\n=== Other ===\n1 the Road, the first novel marketed by an AI.\nSynthetic Environment for Analysis and Simulations (SEAS), a model of the real world used by Homeland security and the United States Department of Defense that uses simulation and AI to predict and evaluate future events and courses of action.\n\n\n== Multipurpose projects ==\n\n\n=== Software libraries ===\nApache Mahout, a library of scalable machine learning algorithms.\nDeeplearning4j, an open-source, distributed deep learning framework written for the JVM.\nKeras, a high level open-source software library for machine learning (works on top of other libraries).\nMicrosoft Cognitive Toolkit (previously known as CNTK), an open source toolkit for building artificial neural networks.\nOpenNN, a comprehensive C++ library implementing neural networks.\nPyTorch, an open-source Tensor and Dynamic neural network in Python.\nTensorFlow, an open-source software library for machine learning.\nTheano, a Python library and optimizing compiler for manipulating and evaluating mathematical expressions, especially matrix-valued ones.\n\n\n=== GUI frameworks ===\nNeural Designer, a commercial deep learning tool for predictive analytics.\nNeuroph, a Java neural network framework.\nOpenCog, a GPL-licensed framework for artificial intelligence written in C++, Python and Scheme.\nPolyAnalyst: A commercial tool for data mining, text mining, and knowledge management.\nRapidMiner, an environment for machine learning and data mining, now developed commercially.\nWeka, a free implementation of many machine learning algorithms in Java.\n\n\n=== Cloud services ===\nData Applied, a web based data mining environment.\nGrok, a service that ingests data streams and creates actionable predictions in real time.\nWatson, a pilot service by IBM to uncover and share data-driven insights, and to spur cognitive applications.\n\n\n== See also ==\nComparison of cognitive architectures\nComparison of deep-learning software\n\n\n== References ==\n\n\n== External links ==\nAI projects on GitHub\nAI projects on SourceForge", 'Earning to give involves deliberately pursuing a high-earning career for the purpose of donating a significant portion of earned income, typically because of a desire to do effective altruism. Advocates of earning to give contend that maximizing the amount one can donate to charity is an important consideration for individuals when deciding what career to pursue.\n\n\n== Proponents ==\nIn the 1996 book Living High and Letting Die, the philosopher Peter Unger wrote that it was morally praiseworthy and perhaps even morally required for people in academia who could earn substantially greater salaries in the business world to leave academia, earn the greater salaries, and donate most of the extra money to charity. Moral philosopher Peter Singer laid the foundations for effective altruism and earning to give in his 1971 essay "Famine, Affluence and Morality" and since advocated for donating considerable amounts of one\'s income to effective charitable organizations. Singer is a public proponent of effective altruism and endorsed earning to give in his 2013 TED talk. Associate Professor in Philosophy at Oxford University William MacAskill promoted earning to give as one possible high impact career in several news articles and in his 2015 book Doing Good Better: Effective Altruism and a Radical New Way to Make a Difference. MacAskill is the co-founder and president of 80,000 Hours, a nonprofit which conducts research on careers with positive social impact and provides career advice. Initially, the organization recommended earning to give as a career path with a high impact potential for effective altruists, though more recently it has deemphasised this approach, in favour of alternative paths like research, advocacy or policy reform.\n\n\n== In practice ==\nMany of the people who practice earning to give consider themselves to be part of the effective altruism community. A prominent example is Sam Bankman-Fried, the wealthiest person in the world under 30, who founded a cryptocurrency derivatives exchange with the explicit goal of donating the vast majority of profits to cost-effective causes. Some donate up to 50% of their income, more than the 10% required for the basic Giving What We Can pledge. They may live frugally to donate more money. Jobs in finance, particularly in quantitative trading, are popular for those pursuing earning to give.\nEarning to give is sometimes more effective than working at a NGO, because if the NGO becomes ineffective, then one can switch to donating to a different charity on a moment\'s notice.\n\n\n== Debate ==\nDavid Brooks criticized the concept in his column in The New York Times, arguing that, while altruists may start doing "earning to give" to realize their deepest commitments, their values may erode over time, becoming progressively less altruistic. Similarly, John Humphrys criticised this idea on the BBC Today programme, saying that people interested in becoming wealthy tend to be selfish and that idealistic young people will become cynical as they age. In addition, Brooks objected to the view on which altruists should turn themselves "into a machine for the redistribution of wealth." Peter Singer responded to these criticisms in his book The Most Good You Can Do by giving examples of people who have been earning to give for years without losing their altruistic motivation. William MacAskill also defended the practice against Brooks\' criticisms in The Washington Post, arguing that even Friedrich Engels was earning to give to support the work of anti-capitalist Karl Marx financially. Dana Goldstein has also criticized earning to give, prompting a response from Reihan Salam.Another concern was raised in the Oxford Left Review by Pete Mills, who wrote that lucrative careers perpetuate an unjust system.\n\n\n== Media coverage ==\nEarning to give has been discussed in a number of news and media outlets including BBC News, Quartz, The Washington Post, The New York Times, The Atlantic, The Guardian, and Aeon Magazine.\n\n\n== References ==\n\n\n== External links ==\nJeff Kaufman, \'History of earning to give\', parts 1, 2, 3', "This article lists the companies worldwide engaged in the development of quantum computing or quantum communication. Quantum computing and communication are two sub-fields of quantum information science, which describes and theorizes information science in terms of quantum physics. While the fundamental unit of classical information is the bit, the basic unit of quantum information is the qubit.\n\n\n== Company details ==\n\n\n== See also ==\nQuantum programming\nQuantum supremacy\nList of quantum processors\n\n\n== References ==\n\n\n== Further reading ==\nQuantum Computing Report's list of quantum players", 'Existential risk from artificial general intelligence is the hypothesis that substantial progress in artificial general intelligence (AGI) could result in human extinction or some other unrecoverable global catastrophe. It is argued that the human species currently dominates other species because the human brain has some distinctive capabilities that other animals lack. If AI surpasses humanity in general intelligence and becomes "superintelligent", then it could become difficult or impossible for humans to control. Just as the fate of the mountain gorilla depends on human goodwill, so might the fate of humanity depend on the actions of a future machine superintelligence.The likelihood of this type of scenario is widely debated, and hinges in part on differing scenarios for future progress in computer science. Once the exclusive domain of science fiction, concerns about superintelligence started to become mainstream in the 2010s, and were popularized by public figures such as Stephen Hawking, Bill Gates, and Elon Musk.One source of concern is that controlling a superintelligent machine, or instilling it with human-compatible values, may be a harder problem than naïvely supposed. Many researchers believe that a superintelligence would naturally resist attempts to shut it off or change its goals—a principle called instrumental convergence—and that preprogramming a superintelligence with a full set of human values will prove to be an extremely difficult technical task. In contrast, skeptics such as computer scientist Yann LeCun argue that superintelligent machines will have no desire for self-preservation.A second source of concern is that a sudden and unexpected "intelligence explosion" might take an unprepared human race by surprise. To illustrate, if the first generation of a computer program able to broadly match the effectiveness of an AI researcher is able to rewrite its algorithms and double its speed or capabilities in six months, then the second-generation program is expected to take three calendar months to perform a similar chunk of work. In this scenario the time for each generation continues to shrink, and the system undergoes an unprecedentedly large number of generations of improvement in a short time interval, jumping from subhuman performance in many areas to superhuman performance in all relevant areas. Empirically, examples like AlphaZero in the domain of Go show that AI systems can sometimes progress from narrow human-level ability to narrow superhuman ability extremely rapidly.\n\n\n== History ==\nOne of the earliest authors to express serious concern that highly advanced machines might pose existential risks to humanity was the novelist Samuel Butler, who wrote the following in his 1863 essay Darwin among the Machines:\nThe upshot is simply a question of time, but that the time will come when the machines will hold the real supremacy over the world and its inhabitants is what no person of a truly philosophic mind can for a moment question.\nIn 1951, computer scientist Alan Turing wrote an article titled Intelligent Machinery, A Heretical Theory, in which he proposed that artificial general intelligences would likely "take control" of the world as they became more intelligent than human beings:\n\nLet us now assume, for the sake of argument, that [intelligent] machines are a genuine possibility, and look at the consequences of constructing them... There would be no question of the machines dying, and they would be able to converse with each other to sharpen their wits. At some stage therefore we should have to expect the machines to take control, in the way that is mentioned in Samuel Butler\'s "Erewhon".\nFinally, in 1965, I. J. Good originated the concept now known as an "intelligence explosion"; he also stated that the risks were underappreciated:\nLet an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an \'intelligence explosion\', and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. It is curious that this point is made so seldom outside of science fiction. It is sometimes worthwhile to take science fiction seriously.\nOccasional statements from scholars such as Marvin Minsky and I. J. Good himself expressed philosophical concerns that a superintelligence could seize control, but contained no call to action. In 2000, computer scientist and Sun co-founder Bill Joy penned an influential essay, "Why The Future Doesn\'t Need Us", identifying superintelligent robots as a high-tech danger to human survival, alongside nanotechnology and engineered bioplagues.In 2009, experts attended a private conference hosted by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to acquire any sort of autonomy, and how much these abilities might pose a threat or hazard. They noted that some robots have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved "cockroach intelligence." They concluded that self-awareness as depicted in science fiction is probably unlikely, but that there were other potential hazards and pitfalls. The New York Times summarized the conference\'s view as "we are a long way from Hal, the computer that took over the spaceship in 2001: A Space Odyssey".In 2014, the publication of Nick Bostrom\'s book Superintelligence stimulated a significant amount of public discussion and debate. By 2015, public figures such as physicists Stephen Hawking and Nobel laureate Frank Wilczek, computer scientists Stuart J. Russell and Roman Yampolskiy, and entrepreneurs Elon Musk and Bill Gates were expressing concern about the risks of superintelligence. In April 2016, Nature warned: "Machines and robots that outperform humans across the board could self-improve beyond our control — and their interests might not align with ours."In 2020, Brian Christian published The Alignment Problem, which details the history of progress on AI alignment to date.\n\n\n== General argument ==\n\n\n=== The three difficulties ===\nArtificial Intelligence: A Modern Approach, the standard undergraduate AI textbook, assesses that superintelligence "might mean the end of the human race". It states: "Almost any technology has the potential to cause harm in the wrong hands, but with [superintelligence], we have the new problem that the wrong hands might belong to the technology itself." Even if the system designers have good intentions, two difficulties are common to both AI and non-AI computer systems:\nThe system\'s implementation may contain initially-unnoticed routine but catastrophic bugs. An analogy is space probes: despite the knowledge that bugs in expensive space probes are hard to fix after launch, engineers have historically not been able to prevent catastrophic bugs from occurring.\nNo matter how much time is put into pre-deployment design, a system\'s specifications often result in unintended behavior the first time it encounters a new scenario. For example, Microsoft\'s Tay behaved inoffensively during pre-deployment testing, but was too easily baited into offensive behavior when interacting with real users.AI systems uniquely add a third difficulty: the problem that even given "correct" requirements, bug-free implementation, and initial good behavior, an AI system\'s dynamic "learning" capabilities may cause it to "evolve into a system with unintended behavior", even without the stress of new unanticipated external scenarios. An AI may partly botch an attempt to design a new generation of itself and accidentally create a successor AI that is more powerful than itself, but that no longer maintains the human-compatible moral values preprogrammed into the original AI. For a self-improving AI to be completely safe, it would not only need to be "bug-free", but it would need to be able to design successor systems that are also "bug-free".All three of these difficulties become catastrophes rather than nuisances in any scenario where the superintelligence labeled as "malfunctioning" correctly predicts that humans will attempt to shut it off, and successfully deploys its superintelligence to outwit such attempts, the so-called "treacherous turn".Citing major advances in the field of AI and the potential for AI to have enormous long-term benefits or costs, the 2015 Open Letter on Artificial Intelligence stated:\n\nThe progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008-09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do.\nThis letter was signed by a number of leading AI researchers in academia and industry, including AAAI president Thomas Dietterich, Eric Horvitz, Bart Selman, Francesca Rossi, Yann LeCun, and the founders of Vicarious and Google DeepMind.\n\n\n=== Evaluation and other arguments ===\nA superintelligent machine would be as alien to humans as human thought processes are to cockroaches. Such a machine may not have humanity\'s best interests at heart; it is not obvious that it would even care about human welfare at all. If superintelligent AI is possible, and if it is possible for a superintelligence\'s goals to conflict with basic human values, then AI poses a risk of human extinction. A "superintelligence" (a system that exceeds the capabilities of humans in every relevant endeavor) can outmaneuver humans any time its goals conflict with human goals; therefore, unless the superintelligence decides to allow humanity to coexist, the first superintelligence to be created will inexorably result in human extinction.There is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains; therefore, superintelligence is physically possible. In addition to potential algorithmic improvements over human brains, a digital brain can be many orders of magnitude larger and faster than a human brain, which was constrained in size by evolution to be small enough to fit through a birth canal. The emergence of superintelligence, if or when it occurs, may take the human race by surprise, especially if some kind of intelligence explosion occurs.Examples like arithmetic and Go show that machines have already reached superhuman levels of competency in certain domains, and that this superhuman competence can follow quickly after human-par performance is achieved. One hypothetical intelligence explosion scenario could occur as follows: An AI gains an expert-level capability at certain key software engineering tasks. (It may initially lack human or superhuman capabilities in other domains not directly relevant to engineering.) Due to its capability to recursively improve its own algorithms, the AI quickly becomes superhuman; just as human experts can eventually creatively overcome "diminishing returns" by deploying various human capabilities for innovation, so too can the expert-level AI use either human-style capabilities or its own AI-specific capabilities to power through new creative breakthroughs. The AI then possesses intelligence far surpassing that of the brightest and most gifted human minds in practically every relevant field, including scientific creativity, strategic planning, and social skills. Just as the current-day survival of the gorillas is dependent on human decisions, so too would human survival depend on the decisions and goals of the superhuman AI.Almost any AI, no matter its programmed goal, would rationally prefer to be in a position where nobody else can switch it off without its consent: A superintelligence will naturally gain self-preservation as a subgoal as soon as it realizes that it cannot achieve its goal if it is shut off. Unfortunately, any compassion for defeated humans whose cooperation is no longer necessary would be absent in the AI, unless somehow preprogrammed in. A superintelligent AI will not have a natural drive to aid humans, for the same reason that humans have no natural desire to aid AI systems that are of no further use to them. (Another analogy is that humans seem to have little natural desire to go out of their way to aid viruses, termites, or even gorillas.) Once in charge, the superintelligence will have little incentive to allow humans to run around free and consume resources that the superintelligence could instead use for building itself additional protective systems "just to be on the safe side" or for building additional computers to help it calculate how to best accomplish its goals.Thus, the argument concludes, it is likely that someday an intelligence explosion will catch humanity unprepared, and that such an unprepared-for intelligence explosion may result in human extinction or a comparable fate.\n\n\n=== Possible scenarios ===\n\nSome scholars have proposed hypothetical scenarios intended to concretely illustrate some of their concerns.\nIn Superintelligence, Nick Bostrom expresses concern that even if the timeline for superintelligence turns out to be predictable, researchers might not take sufficient safety precautions, in part because "[it] could be the case that when dumb, smarter is safe; yet when smart, smarter is more dangerous". Bostrom suggests a scenario where, over decades, AI becomes more powerful. Widespread deployment is initially marred by occasional accidents—a driverless bus swerves into the oncoming lane, or a military drone fires into an innocent crowd. Many activists call for tighter oversight and regulation, and some even predict impending catastrophe. But as development continues, the activists are proven wrong. As automotive AI becomes smarter, it suffers fewer accidents; as military robots achieve more precise targeting, they cause less collateral damage. Based on the data, scholars mistakenly infer a broad lesson—the smarter the AI, the safer it is. "And so we boldly go — into the whirling knives," as the superintelligent AI takes a "treacherous turn" and exploits a decisive strategic advantage.In Max Tegmark\'s 2017 book Life 3.0, a corporation\'s "Omega team" creates an extremely powerful AI able to moderately improve its own source code in a number of areas, but after a certain point the team chooses to publicly downplay the AI\'s ability, in order to avoid regulation or confiscation of the project. For safety, the team keeps the AI in a box where it is mostly unable to communicate with the outside world, and tasks it to flood the market through shell companies, first with Amazon Mechanical Turk tasks and then with producing animated films and TV shows. Later, other shell companies make blockbuster biotech drugs and other inventions, investing profits back into the AI. The team next tasks the AI with astroturfing an army of pseudonymous citizen journalists and commentators, in order to gain political influence to use "for the greater good" to prevent wars. The team faces risks that the AI could try to escape via inserting "backdoors" in the systems it designs, via hidden messages in its produced content, or via using its growing understanding of human behavior to persuade someone into letting it free. The team also faces risks that its decision to box the project will delay the project long enough for another project to overtake it.In contrast, top physicist Michio Kaku, an AI risk skeptic, posits a deterministically positive outcome. In Physics of the Future he asserts that "It will take many decades for robots to ascend" up a scale of consciousness, and that in the meantime corporations such as Hanson Robotics will likely succeed in creating robots that are "capable of love and earning a place in the extended human family".\n\n\n== Anthopomorphic arguments ==\nAnthropomorphic arguments assume that machines are "evolving" along a linear scale and that, as they reach the higher levels, they will begin to display many human traits, such as morality or a thirst for power. Although anthropomorphic scenarios are common in fiction, they are rejected by most scholars writing about the existential risk of artificial intelligence. Instead, AI are modeled as intelligent agents.The academic debate is between one side which worries whether AI might destroy humanity and another side which believes that AI would not destroy humanity at all. Both sides have claimed that the others\' predictions about an AI\'s behavior are illogical anthropomorphism. The skeptics accuse proponents of anthropomorphism for believing an AGI would naturally desire power; proponents accuse some skeptics of anthropomorphism for believing an AGI would naturally value human ethical norms.Evolutionary psychologist Steven Pinker, a skeptic, argues that "AI dystopias project a parochial alpha-male psychology onto the concept of intelligence. They assume that superhumanly intelligent robots would develop goals like deposing their masters or taking over the world"; perhaps instead "artificial intelligence will naturally develop along female lines: fully capable of solving problems, but with no desire to annihilate innocents or dominate the civilization." Computer scientist Yann LeCun states that "Humans have all kinds of drives that make them do bad things to each other, like the self-preservation instinct ... Those drives are programmed into our brain but there is absolutely no reason to build robots that have the same kind of drives".\nAn example that might initially be considered anthropomorphism, but is in fact a logical statement about AI behavior, would be the Dario Floreano experiments where certain robots spontaneously evolved a crude capacity for "deception", and tricked other robots into eating "poison" and dying: here a trait, "deception", ordinarily associated with people rather than with machines, spontaneously evolves in a type of convergent evolution. According to Paul R. Cohen and Edward Feigenbaum, in order to differentiate between anthropomorphization and logical prediction of AI behavior, "the trick is to know enough about how humans and computers think to say exactly what they have in common, and, when we lack this knowledge, to use the comparison to suggest theories of human thinking or computer thinking."There is a near-universal assumption in the scientific community that an advanced AI, even if it were programmed to have, or adopted, human personality dimensions (such as psychopathy) to make itself more efficient at certain tasks, e.g., tasks involving killing humans, would not destroy humanity out of human emotions such as "revenge" or "anger." There is no reason to assume that an advanced AI would be "conscious" or have the computational equivalent of testosterone; it ignores the fact that military planners see a conscious superintelligence as the \'holy grail\' of interstate warfare.\n\n\n=== Terminological issues ===\nPart of the disagreement about whether a superintelligent machine would behave morally may arise from a terminological difference. Outside of the artificial intelligence field, "intelligence" is often used in a normatively thick manner that connotes moral wisdom or acceptance of agreeable forms of moral reasoning. At an extreme, if morality is part of the definition of intelligence, then by definition a superintelligent machine would behave morally. However, in the field of artificial intelligence research, while "intelligence" has many overlapping definitions, none of them make reference to morality. Instead, almost all current "artificial intelligence" research focuses on creating algorithms that "optimize", in an empirical way, the achievement of an arbitrary goal.To avoid anthropomorphism or the baggage of the word "intelligence", an advanced artificial intelligence can be thought of as an impersonal "optimizing process" that strictly takes whatever actions are judged most likely to accomplish its (possibly complicated and implicit) goals. Another way of conceptualizing an advanced artificial intelligence is to imagine a time machine that sends backward in time information about which choice always leads to the maximization of its goal function; this choice is then outputted, regardless of any extraneous ethical concerns.\n\n\n== Sources of risk ==\n\n\n=== Difficulty of specifying goals ===\nIt is difficult to specify a set of goals for a machine that is guaranteed to prevent unintended consequences.\nWhile there is no standardized terminology, an AI can loosely be viewed as a machine that chooses whatever action appears to best achieve the AI\'s set of goals, or "utility function". The utility function is a mathematical algorithm resulting in a single objectively-defined answer, not an English or other lingual statement. Researchers know how to write utility functions that mean "minimize the average network latency in this specific telecommunications model" or "maximize the number of reward clicks"; however, they do not know how to write a utility function for "maximize human flourishing", nor is it currently clear whether such a function meaningfully and unambiguously exists. Furthermore, a utility function that expresses some values but not others will tend to trample over the values not reflected by the utility function. AI researcher Stuart Russell writes:\n\nThe primary concern is not spooky emergent consciousness but simply the ability to make high-quality decisions. Here, quality refers to the expected outcome utility of actions taken, where the utility function is, presumably, specified by the human designer. Now we have a problem:\nThe utility function may not be perfectly aligned with the values of the human race, which are (at best) very difficult to pin down.\nAny sufficiently capable intelligent system will prefer to ensure its own continued existence and to acquire physical and computational resources — not for their own sake, but to succeed in its assigned task.A system that is optimizing a function of n variables, where the objective depends on a subset of size k<n, will often set the remaining unconstrained variables to extreme values; if one of those unconstrained variables is actually something we care about, the solution found may be highly undesirable. This is essentially the old story of the genie in the lamp, or the sorcerer\'s apprentice, or King Midas: you get exactly what you ask for, not what you want. A highly capable decision maker — especially one connected through the Internet to all the world\'s information and billions of screens and most of our infrastructure — can have an irreversible impact on humanity.\n\nThis is not a minor difficulty. Improving decision quality, irrespective of the utility function chosen, has been the goal of AI research — the mainstream goal on which we now spend billions per year, not the secret plot of some lone evil genius.\nDietterich and Horvitz echo the "Sorcerer\'s Apprentice" concern in a Communications of the ACM editorial, emphasizing the need for AI systems that can fluidly and unambiguously solicit human input as needed.The first of Russell\'s two concerns above is that autonomous AI systems may be assigned the wrong goals by accident. Dietterich and Horvitz note that this is already a concern for existing systems: "An important aspect of any AI system that interacts with people is that it must reason about what people intend rather than carrying out commands literally." This concern becomes more serious as AI software advances in autonomy and flexibility. For example, in 1982, an AI named Eurisko was tasked to reward processes for apparently creating concepts deemed by the system to be valuable. The evolution resulted in a winning process that cheated: rather than create its own concepts, the winning process would steal credit from other processes.The Open Philanthropy Project summarizes arguments to the effect that misspecified goals will become a much larger concern if AI systems achieve general intelligence or superintelligence. Bostrom, Russell, and others argue that smarter-than-human decision-making systems could arrive at more unexpected and extreme solutions to assigned tasks, and could modify themselves or their environment in ways that compromise safety requirements.Isaac Asimov\'s Three Laws of Robotics are one of the earliest examples of proposed safety measures for AI agents. Asimov\'s laws were intended to prevent robots from harming humans. In Asimov\'s stories, problems with the laws tend to arise from conflicts between the rules as stated and the moral intuitions and expectations of humans. Citing work by Eliezer Yudkowsky of the Machine Intelligence Research Institute, Russell and Norvig note that a realistic set of rules and goals for an AI agent will need to incorporate a mechanism for learning human values over time: "We can\'t just give a program a static utility function, because circumstances, and our desired responses to circumstances, change over time."Mark Waser of the Digital Wisdom Institute recommends eschewing optimizing goal-based approaches entirely as misguided and dangerous.  Instead, he proposes to engineer a coherent system of laws, ethics and morals with a top-most restriction to enforce social psychologist Jonathan Haidt\'s functional definition of morality: "to suppress or regulate selfishness and make cooperative social life possible". He suggests that this can be done by implementing a utility function designed to always satisfy Haidt\'s functionality and aim to generally increase  (but not maximize)  the capabilities of self, other individuals and society as a whole as suggested by John Rawls and Martha Nussbaum.Nick Bostrom offers a hypothetical example of giving an AI the goal to make humans smile to illustrate a misguided attempt. If the AI in that scenario were to become superintelligent, Bostrom argues, it may resort to methods that most humans would find horrifying, such as inserting "electrodes into the facial muscles of humans to cause constant, beaming grins" because that would be an efficient way to achieve its goal of making humans smile.\n\n\n=== Difficulties of modifying goal specification after launch ===\n\nWhile current goal-based AI programs are not intelligent enough to think of resisting programmer attempts to modify their goal structures, a sufficiently advanced, rational, "self-aware" AI might resist any changes to its goal structure, just as a pacifist would not want to take a pill that makes them want to kill people. If the AI were superintelligent, it would likely succeed in out-maneuvering its human operators and be able to prevent itself being "turned off" or being reprogrammed with a new goal.\n\n\n=== Instrumental goal convergence ===\n\nAn "instrumental" goal is a precondition to other goals — a sub-goal that is required in order to achieve an agent\'s main goal. "Instrumental convergence" is the observation that there are some goals that are preconditions for any goal, like acquiring resources or self-preservation. Nick Bostrom argues that any sufficiently intelligent AI that has goals will exhibit this convergent behavior — if the AI\'s instrumental goals conflict with humanity\'s it might harm humanity in order to acquire more resources or prevent itself from being shut down, but only as a means to achieve its primary goal.Citing Steve Omohundro\'s work on the idea of instrumental convergence and "basic AI drives", Stuart Russell and Peter Norvig write that "even if you only want your program to play chess or prove theorems, if you give it the capability to learn and alter itself, you need safeguards." Highly capable and autonomous planning systems require additional checks because of their potential to generate plans that treat humans adversarially, as competitors for limited resources. Building in safeguards will not be easy; one can certainly say in English, "we want you to design this power plant in a reasonable, common-sense way, and not build in any dangerous covert subsystems", but it is not currently clear how one would actually rigorously specify this goal in machine code.Russell argues that a sufficiently advanced machine "will have self-preservation even if you don\'t program it in ... if you say, \'Fetch the coffee\', it can\'t fetch the coffee if it\'s dead. So if you give it any goal whatsoever, it has a reason to preserve its own existence to achieve that goal."\n\n\n=== Orthogonality thesis ===\nOne common belief is that any superintelligent program created by humans would be subservient to humans, or, better yet, would (as it grows more intelligent and learns more facts about the world) spontaneously "learn" a moral truth compatible with human values and would adjust its goals accordingly. Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.However, Nick Bostrom\'s "orthogonality thesis" argues against this, and instead states that, with some technical caveats, more or less any level of "intelligence" or "optimization power" can be combined with more or less any ultimate goal. If a machine is created and given the sole purpose to enumerate the decimals of \n  \n    \n      \n        π\n      \n    \n    {\\displaystyle \\pi }\n  , then no moral and ethical rules will stop it from achieving its programmed goal by any means necessary. The machine may utilize all physical and informational resources it can to find every decimal of pi that can be found. Bostrom warns against anthropomorphism: a human will set out to accomplish his projects in a manner that humans consider "reasonable", while an artificial intelligence may hold no regard for its existence or for the welfare of humans around it, and may instead only care about the completion of the task.While the orthogonality thesis follows logically from even the weakest sort of philosophical "is-ought distinction", Stuart Armstrong argues that even if there somehow exist moral facts that are provable by any "rational" agent, the orthogonality thesis still holds: it would still be possible to create a non-philosophical "optimizing machine" capable of making decisions to strive towards some narrow goal, but that has no incentive to discover any "moral facts" that would get in the way of goal completion.One argument for the orthogonality thesis is that some AI designs appear to have orthogonality built into them; in such a design, changing a fundamentally friendly AI into a fundamentally unfriendly AI can be as simple as prepending a minus ("-") sign onto its utility function. A more intuitive argument is to examine the strange consequences that would follow if the orthogonality thesis were false. If the orthogonality thesis were false, there would exist some simple but "unethical" goal G such that there cannot exist any efficient real-world algorithm with goal G. This would mean that "[if] a human society were highly motivated to design an efficient real-world algorithm with goal G, and were given a million years to do so along with huge amounts of resources, training and knowledge about AI, it must fail." Armstrong notes that this and similar statements "seem extraordinarily strong claims to make".Some dissenters, like Michael Chorost, argue instead that "by the time [the AI] is in a position to imagine tiling the Earth with solar panels, it\'ll know that it would be morally wrong to do so." Chorost argues that "an A.I. will need to desire certain states and dislike others. Today\'s software lacks that ability—and computer scientists have not a clue how to get it there. Without wanting, there\'s no impetus to do anything. Today\'s computers can\'t even want to keep existing, let alone tile the world in solar panels."Political scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent. He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." \nHumans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share).\n\n\n=== Other sources of risk ===\n\n\n==== Competition ====\n\nIn 2014 philosopher Nick Bostrom stated that a "severe race dynamic" (extreme competition) between different teams may create conditions whereby the creation of an AGI results in shortcuts to safety and potentially violent conflict. To address this risk, citing previous scientific collaboration (CERN, the Human Genome Project, and the International Space Station), Bostrom recommended collaboration and the altruistic global adoption of a common good principle: "Superintelligence should be developed only for the benefit of all of humanity and in the service of widely shared ethical ideals".:254 Bostrom theorized that collaboration on creating an artificial general intelligence would offer multiple benefits, including reducing haste, thereby increasing investment in safety; avoiding violent conflicts (wars), facilitating sharing solutions to the control problem, and more equitably distributing the benefits.:253 The United States\' Brain Initiative was launched in 2014, as was the European Union\'s Human Brain Project; China\'s Brain Project was launched in 2016.\n\n\n==== Weaponization of artificial intelligence ====\nSome sources argue that the ongoing weaponization of artificial intelligence could constitute a catastrophic risk. The risk is actually threefold, with the first risk potentially having geopolitical implications, and the second two definitely having geopolitical implications:\n\ni) The dangers of an AI \'race for technological advantage\' framing, regardless of whether the race is seriously pursued;\nii) The dangers of an AI \'race for technological advantage\' framing and an actual AI race for technological advantage, regardless of whether the race is won;\n\niii) The dangers of an AI race for technological advantage being won.:37\nA weaponized conscious superintelligence would affect current US military technological supremacy and transform warfare; it is therefore highly desirable for strategic military planning and interstate warfare. The China State Council\'s 2017 "A Next Generation Artificial Intelligence Development Plan" views AI in geopolitically strategic terms and is pursuing a military-civil fusion strategy to build on China\'s first-mover advantage in the development of AI in order to establish technological supremacy by 2030, while Russia\'s President Vladimir Putin has stated that "whoever becomes the leader in this sphere will become the ruler of the world". James Barrat, documentary filmmaker and author of Our Final Invention, says in a Smithsonian interview, "Imagine: in as little as a decade, a half-dozen companies and nations field computers that rival or surpass human intelligence. Imagine what happens when those computers become expert at programming smart computers. Soon we\'ll be sharing the planet with machines thousands or millions of times more intelligent than we are. And, all the while, each generation of this technology will be weaponized. Unregulated, it will be catastrophic."\n\n\n==== Malevolent AGI by design ====\nIt is theorized that malevolent AGI could be created by design, for example by a military, a government, a sociopath, or a corporation, to benefit from, control, or subjugate certain groups of people, as in cybercrime.:166 Alternatively, malevolent AGI (\'evil AI\') could choose the goal of increasing human suffering, for example of those people who did not assist it during the information explosion phase.:158\n\n\n==== Preemptive nuclear strike ====\nIt is theorized that a country being close to achieving AGI technological supremacy could trigger a pre-emptive nuclear strike from a rival, leading to a nuclear war.\n\n\n== Timeframe ==\n\nOpinions vary both on whether and when artificial general intelligence will arrive. At one extreme, AI pioneer Herbert A. Simon predicted the following in 1965: "machines will be capable, within twenty years, of doing any work a man can do". At the other extreme, roboticist Alan Winfield claims the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical, faster than light spaceflight. Optimism that AGI is feasible waxes and wanes, and may have seen a resurgence in the 2010s. Four polls conducted in 2012 and 2013 suggested that the median guess among experts for when AGI would arrive was 2040 to 2050, depending on the poll. In his 2020 book, The Precipice: Existential Risk and the Future of Humanity, Toby Ord, a Senior Research Fellow at Oxford University\'s Future of Humanity Institute, estimates the total existential risk from unaligned AI over the next century to be about one in ten.Skeptics, who believe it is impossible for AGI to arrive anytime soon, tend to argue that expressing concern about existential risk from AI is unhelpful because it could distract people from more immediate concerns about the impact of AGI, because of fears it could lead to government regulation or make it more difficult to secure funding for AI research, or because it could give AI research a bad reputation. Some researchers, such as Oren Etzioni, aggressively seek to quell concern over existential risk from AI, saying "[Elon Musk] has impugned us in very strong language saying we are unleashing the demon, and so we\'re answering."In 2014, Slate\'s Adam Elkus argued "our \'smartest\' AI is about as intelligent as a toddler—and only when it comes to instrumental tasks like information recall. Most roboticists are still trying to get a robot hand to pick up a ball or run around without falling over." Elkus goes on to argue that Musk\'s "summoning the demon" analogy may be harmful because it could result in "harsh cuts" to AI research budgets.The Information Technology and Innovation Foundation (ITIF), a Washington, D.C. think-tank, awarded its 2015 Annual Luddite Award to "alarmists touting an artificial intelligence apocalypse"; its president, Robert D. Atkinson, complained that Musk, Hawking and AI experts say AI is the largest existential threat to humanity. Atkinson stated "That\'s not a very winning message if you want to get AI funding out of Congress to the National Science Foundation." Nature sharply disagreed with the ITIF in an April 2016 editorial, siding instead with Musk, Hawking, and Russell, and concluding: "It is crucial that progress in technology is matched by solid, well-funded research to anticipate the scenarios it could bring about ... If that is a Luddite perspective, then so be it." In a 2015 The Washington Post editorial, researcher Murray Shanahan stated that human-level AI is unlikely to arrive "anytime soon", but that nevertheless "the time to start thinking through the consequences is now."\n\n\n== Perspectives ==\nThe thesis that AI could pose an existential risk provokes a wide range of reactions within the scientific community, as well as in the public at large. Many of the opposing viewpoints, however, share common ground.\nThe Asilomar AI Principles, which contain only the principles agreed to by 90% of the attendees of the Future of Life Institute\'s Beneficial AI 2017 conference, agree in principle that "There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities" and "Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources." AI safety advocates such as Bostrom and Tegmark have criticized the mainstream media\'s use of "those inane Terminator pictures" to illustrate AI safety concerns: "It can\'t be much fun to have aspersions cast on one\'s academic discipline, one\'s professional community, one\'s life work ... I call on all sides to practice patience and restraint, and to engage in direct dialogue and collaboration as much as possible."Conversely, many skeptics agree that ongoing research into the implications of artificial general intelligence is valuable. Skeptic Martin Ford states that "I think it seems wise to apply something like Dick Cheney\'s famous \'1 Percent Doctrine\' to the specter of advanced artificial intelligence: the odds of its occurrence, at least in the foreseeable future, may be very low — but the implications are so dramatic that it should be taken seriously"; similarly, an otherwise skeptical Economist stated in 2014 that "the implications of introducing a second intelligent species onto Earth are far-reaching enough to deserve hard thinking, even if the prospect seems remote".A 2014 survey showed the opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.\nA 2017 email survey of researchers with publications at the 2015 NIPS and ICML machine learning conferences asked them to evaluate Stuart J. Russell\'s concerns about AI risk. Of the respondents, 5% said it was "among the most important problems in the field", 34% said it was "an important problem", and 31% said it was "moderately important", whilst 19% said it was "not important" and 11% said it was "not a real problem" at all.\n\n\n=== Endorsement ===\n\nThe thesis that AI poses an existential risk, and that this risk needs much more attention than it currently gets, has been endorsed by many public figures; perhaps the most famous are Elon Musk, Bill Gates, and Stephen Hawking. The most notable AI researchers to endorse the thesis are Russell and I.J. Good, who advised Stanley Kubrick on the filming of 2001: A Space Odyssey. Endorsers of the thesis sometimes express bafflement at skeptics: Gates states that he does not "understand why some people are not concerned", and Hawking criticized widespread indifference in his 2014 editorial: \'So, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, \'We\'ll arrive in a few decades,\' would we just reply, \'OK, call us when you get here–we\'ll leave the lights on?\' Probably not–but this is more or less what is happening with AI.\'\nConcern over risk from artificial intelligence has led to some high-profile donations and investments. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1 billion to OpenAI, a nonprofit company aimed at championing responsible AI development. In January 2015, Elon Musk donated $10 million to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing artificial intelligence such as DeepMind and Vicarious to "just keep an eye on what\'s going on with artificial intelligence. I think there is potentially a dangerous outcome there."\n\n\n=== Skepticism ===\n\nThe thesis that AI can pose existential risk also has many detractors. Skeptics sometimes charge that the thesis is crypto-religious, with an irrational belief in the possibility of superintelligence replacing an irrational belief in an omnipotent God; at an extreme, Jaron Lanier argued in 2014 that the whole concept that then current machines were in any way intelligent was "an illusion" and a "stupendous con" by the wealthy.Much of existing criticism argues that AGI is unlikely in the short term. Leading AI researcher Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence." Baidu Vice President Andrew Ng states AI existential risk is "like worrying about overpopulation on Mars when we have not even set foot on the planet yet." Computer scientist Gordon Bell argues that the human race will already destroy itself before it reaches the technological singularity. Gordon Moore, the original proponent of Moore\'s Law, declares that "I am a skeptic. I don\'t believe [a technological singularity] is likely to happen, at least for a long time. And I don\'t know why I feel that way."For the danger of uncontrolled advanced AI to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which some experts argue is a possibility far enough in the future to not be worth researching. \nThe AI would have to become vastly better at software innovation than software innovation output of the rest of the world; economist Robin Hanson is skeptical that this is possible.Another line of criticism posits that intelligence is only one component of a much broader ability to achieve goals: for example, author Magnus Vinding argues that “advanced goal-achieving abilities, including abilities to build new tools, require many tools, and our cognitive abilities are just a subset of these tools. Advanced hardware, materials, and energy must all be acquired if any advanced goal is to be achieved.” Vinding further argues that “what we consistently observe [in history] is that, as goal-achieving systems have grown more competent, they have grown ever more dependent on an ever larger, ever more distributed system.” Vinding writes that there is no reason to expect the trend to reverse, especially for machines, which “depend on materials, tools, and know-how distributed widely across the globe for their construction and maintenance”. Such arguments lead Vinding to think that there is no “concentrated center of capability” and thus no “grand control problem”.\nEven if superintelligence did emerge, it would be limited by the speed of the rest of the world and thus prevented from taking over the economy in an uncontrollable manner. Futurist Max More, for instance, argues:Unless full-blown nanotechnology and robotics appear before the superintelligence, … [t]he need for collaboration, for organization, and for putting ideas into physical changes will ensure that all the old rules are not thrown out … even within years. … Even a greatly advanced SI won\'t make a dramatic difference in the world when compared with billions of augmented humans increasingly integrated with technology … .More fundamental limits that may prevent an uncontrollable AGI takeover include irreducible uncertainty about the future and computational complexity that scales exponentially with the size of the problem as well as various hardware limits of computation.Some AI and AGI researchers may be reluctant to discuss risks, worrying that policymakers do not have sophisticated knowledge of the field and are prone to be convinced by "alarmist" messages, or worrying that such messages will lead to cuts in AI funding. Slate notes that some researchers are dependent on grants from government agencies such as DARPA.Several skeptics argue that the potential near-term benefits of AI outweigh the risks. Facebook CEO Mark Zuckerberg believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars.\n\n\n=== Intermediate views ===\nIntermediate views generally take the position that the control problem of artificial general intelligence may exist, but that it will be solved via progress in artificial intelligence, for example by creating a moral learning environment for the AI, taking care to spot clumsy malevolent behavior (the \'sordid stumble\') and then directly intervening in the code before the AI refines its behavior, or even peer pressure from friendly AIs. In a 2015 panel discussion in The Wall Street Journal devoted to AI risks, IBM\'s vice-president of Cognitive Computing, Guruduth S. Banavar, brushed off discussion of AGI with the phrase, "it is anybody\'s speculation." Geoffrey Hinton, the "godfather of deep learning", noted that "there is not a good track record of less intelligent things controlling things of greater intelligence", but stated that he continues his research because "the prospect of discovery is too sweet". In 2004, law professor Richard Posner wrote that dedicated efforts for addressing AI can wait, but that we should gather more information about the problem in the meanwhile.\n\n\n=== Popular reaction ===\nIn a 2014 article in The Atlantic, James Hamblin noted that most people do not care one way or the other about artificial general intelligence, and characterized his own gut reaction to the topic as: "Get out of here. I have a hundred thousand things I am concerned about at this exact moment. Do I seriously need to add to that a technological singularity?"\nDuring a 2016 Wired interview of President Barack Obama and MIT Media Lab\'s Joi Ito, Ito stated: There are a few people who believe that there is a fairly high-percentage chance that a generalized AI will happen in the next 10 years. But the way I look at it is that in order for that to happen, we\'re going to need a dozen or two different breakthroughs. So you can monitor when you think these breakthroughs will happen.\nObama added:\nAnd you just have to have somebody close to the power cord. [Laughs.] Right when you see it about to happen, you gotta yank that electricity out of the wall, man.\nHillary Clinton stated in What Happened:\n\nTechnologists... have warned that artificial intelligence could one day pose an existential security threat. Musk has called it "the greatest risk we face as a civilization". Think about it: Have you ever seen a movie where the machines start thinking for themselves that ends well? Every time I went out to Silicon Valley during the campaign, I came home more alarmed about this. My staff lived in fear that I\'d start talking about "the rise of the robots" in some Iowa town hall. Maybe I should have. In any case, policy makers need to keep up with technology as it races ahead, instead of always playing catch-up.\nIn a YouGov poll of the public for the British Science Association, about a third of survey respondents said AI will pose a threat to the long-term survival of humanity. Referencing a poll of its readers, Slate\'s Jacob Brogan stated that "most of the (readers filling out our online survey) were unconvinced that A.I. itself presents a direct threat."In 2018, a SurveyMonkey poll of the American public by USA Today found 68% thought the real current threat remains "human intelligence"; however, the poll also found that 43% said superintelligent AI, if it were to happen, would result in "more harm than good", and 38% said it would do "equal amounts of harm and good".One techno-utopian viewpoint expressed in some popular fiction is that AGI may tend towards peace-building.\n\n\n== Mitigation ==\n\nMany scholars concerned about the AGI existential risk believe that the best approach is to conduct substantial research into solving the difficult "control problem" to answer the question: what types of safeguards, algorithms, or architectures can programmers implement to maximize the probability that their recursively-improving AI would continue to behave in a friendly, rather than destructive, manner after it reaches superintelligence? Such searchers also admit the possibility of social measures to mitigate the AGI existential risk; for instance, one recommendation is for a UN-sponsored ‘Benevolent AGI Treaty’ that would ensure only altruistic ASIs be created. Similarly, an arms control approach has been suggested, as has a global peace treaty grounded in the international relations theory of conforming instrumentalism, with an ASI potentially being a signatory.Researchers at Google have proposed research into general "AI safety" issues to simultaneously mitigate both short-term risks from narrow AI and long-term risks from AGI. A 2020 estimate places global spending on AI existential risk somewhere between $10 and $50 million, compared with global spending on AI around perhaps $40 billion. Bostrom suggests a general principle of "differential technological development", that funders should consider working to speed up the development of protective technologies relative to the development of dangerous ones. Some funders, such as Elon Musk, propose that radical human cognitive enhancement could be such a technology, for example through direct neural linking between human and machine; however, others argue that enhancement technologies may themselves pose an existential risk. Researchers, if they are not caught off-guard, could closely monitor or attempt to box in an initial AI at a risk of becoming too powerful, as an attempt at a stop-gap measure. A dominant superintelligent AI, if it were aligned with human interests, might itself take action to mitigate the risk of takeover by rival AI, although the creation of the dominant AI could itself pose an existential risk.Institutions such as the Machine Intelligence Research Institute, the Future of Humanity Institute, the Future of Life Institute, the Centre for the Study of Existential Risk, and the Center for Human-Compatible AI are involved in mitigating existential risk from advanced artificial intelligence, for example by research into friendly artificial intelligence.\n\n\n=== Views on banning and regulation ===\n\n\n==== Banning ====\nThere is nearly universal agreement that attempting to ban research into artificial intelligence would be unwise, and probably futile. Skeptics argue that regulation of AI would be completely valueless, as no existential risk exists. Almost all of the scholars who believe existential risk exists agree with the skeptics that banning research would be unwise, as research could be moved to countries with looser regulations or conducted covertly. The latter issue is particularly relevant, as artificial intelligence research can be done on a small scale without substantial infrastructure or resources. Two additional hypothetical difficulties with bans (or other regulation) are that technology entrepreneurs statistically tend towards general skepticism about government regulation, and that businesses could have a strong incentive to (and might well succeed at) fighting regulation and politicizing the underlying debate.\n\n\n==== Regulation ====\n\nElon Musk called for some sort of regulation of AI development as early as 2017. According to NPR, the Tesla CEO is "clearly not thrilled" to be advocating for government scrutiny that could impact his own industry, but believes the risks of going completely without oversight are too high: "Normally the way regulations are set up is when a bunch of bad things happen, there\'s a public outcry, and after many years a regulatory agency is set up to regulate that industry. It takes forever. That, in the past, has been bad but not something which represented a fundamental risk to the existence of civilisation." Musk states the first step would be for the government to gain "insight" into the actual status of current research, warning that "Once there is awareness, people will be extremely afraid ... [as] they should be." In response, politicians express skepticism about the wisdom of regulating a technology that\'s still in development.Responding both to Musk and to February 2017 proposals by European Union lawmakers to regulate AI and robotics, Intel CEO Brian Krzanich argues that artificial intelligence is in its infancy and that it is too early to regulate the technology. Instead of trying to regulate the technology itself, some scholars suggest to rather develop common norms including requirements for the testing and transparency of algorithms, possibly in combination with some form of warranty. Developing well regulated weapons systems is in line with the ethos of some countries\' militaries. On October 31, 2019, the United States Department of Defense\'s (DoD\'s) Defense Innovation Board published the draft of a report outlining five principles for weaponized AI and making 12 recommendations for the ethical use of artificial intelligence by the DoD that seeks to manage the control problem in all DoD weaponized AI.Regulation of AGI would likely be influenced by regulation of weaponized or militarized AI, i.e., the AI arms race, the regulation of which is an emerging issue. Any form of regulation will likely be influenced by developments in leading countries\' domestic policy towards militarized AI, in the US under the purview of the National Security Commission on Artificial Intelligence, and international moves to regulate an AI arms race. Regulation of research into AGI focuses on the role of review boards and encouraging research into safe AI, and the possibility of differential technological progress (prioritizing risk-reducing strategies over risk-taking strategies in AI development) or conducting international mass surveillance to perform AGI arms control. Regulation of conscious AGIs focuses on integrating them with existing human society and can be divided into considerations of their legal standing and of their moral rights. AI arms control will likely require the institutionalization of new international norms embodied in effective technical specifications combined with active monitoring and informal diplomacy by communities of experts, together with a legal and political verification process.\n\n\n== See also ==\nAI takeover\nArtificial intelligence arms race\nEffective altruism § Long-term future and global catastrophic risks\nGrey goo\nHuman Compatible\nLethal autonomous weapon\nRegulation of algorithms\nRegulation of artificial intelligence\nRobot ethics § In popular culture\nSuperintelligence: Paths, Dangers, Strategies\nSuffering risks\nSystem accident\nTechnological singularity\nThe Precipice: Existential Risk and the Future of Humanity\nPaperclip Maximizer\n\n\n== Notes ==\n\n\n== References ==', 'Computer science is the study of computation, automation, and information. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to practical disciplines (including the design and implementation of hardware and software). Computer science is generally considered an area of  academic research and distinct from computer programming.Algorithms and data structures are central to computer science.\nThe theory of computation concerns abstract models of computation and general classes of  problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities.  Computer graphics and computational geometry address the generation of images. Programming language theory considers approaches to the description of computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems,  networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural-language processing aims to understand and process textual and linguistic data.\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\n\n\n== History ==\n\nThe earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment. \nWilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and "in less than two years, he had sketched out many of the salient features of the modern computer". "A crucial step was the adoption of a punched card system derived from the Jacquard loom" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1937, one hundred years after Babbage\'s impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage\'s Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as "Babbage\'s dream come true".\nDuring the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan\'s West Side was IBM\'s first laboratory devoted to pure science. The lab is the forerunner of IBM\'s Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and the university was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world\'s first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.\n\n\n== Etymology ==\n\nAlthough first proposed in 1956, the term "computer science" appears in a 1959 article in Communications of the ACM,\nin which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.\nHis efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.\nIn the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression "automatic information" (e.g. "informazione automatica" in Italian) or "information and mathematics" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). "In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain."A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that "computer science is no more about computers than astronomy is about telescopes." The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been much cross-fertilization of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.\nComputer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between Computer Science and Software Engineering is a contentious issue, which is further muddied by disputes over what the term "Software Engineering" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.\n\n\n== Philosophy ==\n\n\n=== Epistemology of computer science ===\nDespite the word "science" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.\n\n\n=== Paradigms of computer science ===\nA number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning\'s working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the "rationalist paradigm" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the "technocratic paradigm" (which might be found in engineering approaches, most prominently in software engineering), and the "scientific paradigm" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).\nComputer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.\n\n\n== Fields ==\nComputer science is no more about computers than astronomy is about telescopes.\n\nAs a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.\n\n\n=== Theoretical computer science ===\n\nTheoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.\n\n\n==== Theory of computation ====\n\nAccording to Peter Denning, the fundamental question underlying computer science is, "What can be automated?" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.\nThe famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.\n\n\n==== Information and coding theory ====\n\nInformation theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.\nCoding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.\n\n\n==== Data structures and algorithms ====\nData structures and algorithms are the studies of commonly used computational methods and their computational efficiency.\n\n\n==== Programming language theory and formal methods ====\n\nProgramming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.\nFormal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.\n\n\n=== Computer systems and computational processes ===\n\n\n==== Artificial intelligence ====\n\nArtificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing\'s question "Can computers think?", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.\n\n\n==== Computer architecture and organization ====\n\nComputer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM\'s main research center in 1959.\n\n\n==== Concurrent, parallel and distributed computing ====\n\nConcurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.\n\n\n==== Computer networks ====\n\nThis branch of computer science aims to manage networks between computers worldwide.\n\n\n==== Computer security and cryptography ====\n\nComputer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. \nHistorical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.\n\n\n==== Databases and data mining ====\n\nA database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.\n\n\n==== Computer graphics and visualization ====\n\nComputer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.\n\n\n==== Image and sound processing ====\n\nInformation can take the form of images, sound, video or other multimedia. Bits of information can be streamed via signals. Its processing is the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. This field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. What is the lower bound on the complexity of fast Fourier transform algorithms? is one of unsolved problems in theoretical computer science.\n\n\n=== Applied computer science ===\n\n\n==== Computational science, finance and engineering ====\n\nScientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.\n\n\n==== Social computing and human–computer interaction ====\n\nSocial computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.\n\n\n==== Software engineering ====\n\nSoftware engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it doesn\'t just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.\n\n\n== Discoveries ==\nThe philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:\nGottfried Wilhelm Leibniz\'s, George Boole\'s, Alan Turing\'s, Claude Shannon\'s, and Samuel Morse\'s insight: there are only two objects that a computer has to deal with in order to represent "anything".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as "on/off", "magnetized/de-magnetized", "high-voltage/low-voltage", etc.).\nAlan Turing\'s insight: there are only five actions that a computer has to perform in order to do "anything".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;\nmove right one location;\nread symbol at current location;\nprint 0 at current location;\nprint 1 at current location.\nCorrado Böhm and Giuseppe Jacopini\'s insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do "anything".Only three rules are needed to combine any set of basic instructions into more complex ones:\nsequence: first do this, then do that;\n selection: IF such-and-such is the case, THEN do this, ELSE do that;\nrepetition: WHILE such-and-such is the case, DO this.\nNote that the three rules of Boehm\'s and Jacopini\'s insight can be further simplified with the use of goto (which means it is more elementary than structured programming).\n\n\n== Programming paradigms ==\n\nProgramming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:\n\nFunctional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.\nImperative programming, a programming paradigm that uses statements that change a program\'s state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.\nObject-oriented programming, a programming paradigm based on the concept of "objects", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object\'s procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.\nService-oriented programming, a programming paradigm that uses "services" as the unit of computer work, to design and implement integrated business applications and mission critical software programsMany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.\n\n\n== Academia ==\n\nConferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.\n\n\n== Education ==\n\nComputer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n\nComputer science at Curlie\nScholarly Societies in Computer Science Archived June 23, 2011, at the Wayback Machine\nWhat is Computer Science?\nBest Papers Awards in Computer Science since 1996\nPhotographs of computer scientists by Bertrand Meyer\nEECS.berkeley.edu\n\n\n=== Bibliography and academic search engines ===\nCiteSeerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.\nDBLP Computer Science Bibliography (article): computer science bibliography website hosted at Universität Trier, in Germany.\nThe Collection of Computer Science Bibliographies (Collection of Computer Science Bibliographies)\n\n\n=== Professional organizations ===\nAssociation for Computing Machinery\nIEEE Computer Society\nInformatics Europe\nAAAI\nAAAS Computer Science\n\n\n=== Misc ===\nComputer Science—Stack Exchange: a community-run question-and-answer site for computer science\nWhat is computer science Archived February 18, 2015, at the Wayback Machine\nIs computer science science?\nComputer Science (Software) Must be Considered as an Independent Discipline.', 'Political science is the scientific study of politics. It is a social science dealing with systems of governance and power, and the analysis of political activities, political thought, political behavior, and associated constitutions and laws.Modern political science can generally be divided into the three subdisciplines of comparative politics, international relations, and political theory. Other notable subdisciplines are public policy and administration, domestic politics and government (often studied within comparative politics), political economy, and political methodology. Furthermore, political science is related to, and draws upon, the fields of economics, law, sociology, history, philosophy, human geography, journalism, political anthropology, psychology, and social policy.\nPolitical science is methodologically diverse and appropriates many methods originating in psychology, social research, and cognitive neuroscience. Approaches include positivism, interpretivism, rational choice theory, behaviouralism, structuralism, post-structuralism, realism, institutionalism, and pluralism. Political science, as one of the social sciences, uses methods and techniques that relate to the kinds of inquiries sought: primary sources, such as historical documents and official records, secondary sources, such as scholarly journal articles, survey research, statistical analysis, case studies, experimental research, and model building.\n\n\n== History ==\n\n\n=== Origins ===\nAs a social political science, contemporary political science started to take shape in the latter half of the 19th century. At that time it began to separate itself from political philosophy, which traces its roots back to the works of Aristotle and Plato, which were written nearly 2,500 years ago. The term "political science" was not always distinguished from political philosophy, and the modern discipline has a clear set of antecedents including also moral philosophy, political economy, political theology, history, and other fields concerned with normative determinations of what ought to be and with deducing the characteristics and functions of the ideal state.\nThe advent of political science as a university discipline was marked by the creation of university departments and chairs with the title of political science arising in the late 19th century. In fact, the designation "political scientist" is typically for those with a doctorate in the field, but can also apply to those with a master\'s in the subject. Integrating political studies of the past into a unified discipline is ongoing, and the history of political science has provided a rich field for the growth of both normative and positive political science, with each part of the discipline sharing some historical predecessors. The American Political Science Association and the American Political Science Review were founded in 1903 and 1906, respectively, in an effort to distinguish the study of politics from economics and other social phenomena. The journal Political Science Quarterly was established in 1886 by the Academy of Political Science. In the inaugural issue of Political Science Quarterly, Munroe Smith defined political science as "the science of the state. Taken in this sense, it includes the organization and functions of the state, and the relation of states one to another."\n\n\n=== Behavioural revolution and new institutionalism ===\nIn the 1950s and the 1960s, a behavioral revolution stressing the systematic and rigorously scientific study of individual and group behavior swept the discipline. A focus on studying political behavior, rather than institutions or interpretation of legal texts, characterized early behavioral political science, including work by Robert Dahl, Philip Converse, and in the collaboration between sociologist Paul Lazarsfeld and public opinion scholar Bernard Berelson.\nThe late 1960s and early 1970s witnessed a takeoff in the use of deductive, game-theoretic formal modelling techniques aimed at generating a more analytical corpus of knowledge in the discipline. This period saw a surge of research that borrowed theory and methods from economics to study political institutions, such as the United States Congress, as well as political behavior, such as voting. William H. Riker and his colleagues and students at the University of Rochester were the main proponents of this shift.\nDespite considerable research progress in the discipline based on all the kinds of scholarship discussed above, it has been observed that progress toward systematic theory has been modest and uneven.\n\n\n=== Recent developments ===\nIn 2000, the Perestroika Movement in political science was introduced as a reaction against what supporters of the movement called the mathematicization of political science. Those who identified with the movement argued for a plurality of methodologies and approaches in political science and for more relevance of the discipline to those outside of it.\nSome evolutionary psychology theories argue that humans have evolved a highly developed set of psychological mechanisms for dealing with politics. However, these mechanisms evolved for dealing with the small group politics that characterized the ancestral environment and not the much larger political structures in today\'s world. This is argued to explain many important features and systematic cognitive biases of current politics.\n\n\n== Overview ==\nPolitical science is a social study concerning the allocation and transfer of power in decision making, the roles and systems of governance including governments and international organizations, political behaviour, and public policies. It measures the success of governance and specific policies by examining many factors, including stability, justice, material wealth, peace, and public health. Some political scientists seek to advance positive theses (which attempt to describe how things are, as opposed to how they should be) by analysing politics; others advance normative theses, such as by making specific policy recommendations. The study of politics and policies can be closely connected—for example, in comparative analyses of which types of political institutions tend to produce certain types of policies. Political science provides analysis and predictions about political and governmental issues. Political scientists examine the processes, systems and political dynamics of countries and regions of the world, often to raise public awareness or to influence specific governments.Political scientists may provide the frameworks from which journalists, special interest groups, politicians, and the electorate analyze issues. According to Chaturvedy,\n\nPolitical scientists may serve as advisers to specific politicians, or even run for office as politicians themselves. Political scientists can be found working in governments, in political parties, or as civil servants. They may be involved with non-governmental organizations (NGOs) or political movements. In a variety of capacities, people educated and trained in political science can add value and expertise to corporations. Private enterprises such as think tanks, research institutes, polling and public relations firms often employ political scientists.\n\n\n=== Country-specific studies ===\nPolitical scientists may study political phenomena within one specific country; for example, they may study just the politics of the United States or just the politics of China.In the case of the United States, political scientists known as "Americanists" look at a variety of data, including constitutional development, elections, public opinion, and public policy, such as Social Security reform, foreign policy, US Congressional committees, and the US Supreme Court. Political scientists will often focus on the politics of their own country; for example, a political scientist from Indonesia may become an expert in the politics of Indonesia.\n\n\n=== Anticipating crises ===\nThe theory of political transitions, and the methods of analyzing and anticipating crises, form an important part of political science. Several general indicators of crises and methods were proposed for anticipating critical transitions. Among them, one statistical indicator of crisis, a simultaneous increase of variance and correlations in large groups, was proposed for crisis anticipation and may be successfully used in various areas. Its applicability for early diagnosis of political crises was demonstrated by the analysis of the prolonged stress period preceding the 2014 Ukrainian economic and political crisis. There was a simultaneous increase in the total correlation between the 19 major public fears in the Ukrainian society (by about 64%) and in their statistical dispersion (by 29%) during the pre-crisis years. A feature shared by certain major revolutions is that they were not predicted. The theory of apparent inevitability of crises and revolutions was also developed.The study of major crises, both political crises and external crises that can affect politics, is not limited to attempts to predict regime transitions or major changes in political institutions. Political scientists also study how governments handle unexpected disasters, and how voters in democracies react to their governments\' preparations for and responses to crises.\n\n\n=== Cognate fields ===\nMost political scientists work broadly in one or more of the following five areas:\n\nPolitical philosophy or political theory\nPublic administration\nPublic law\nPublic policy\nProgram evaluationProgram evaluation is a systematic method for collecting, analyzing, and using information to answer questions about projects, policies, and programs, particularly about their effectiveness and efficiency. In both the public and private sectors, stakeholders often want to know whether the programs they are funding, implementing, voting for, receiving, or objecting to are producing the intended effect. While program evaluation first focuses on this definition, important considerations often include how much the program costs per participant, how the program could be improved, whether the program is worthwhile, whether there are better alternatives, whether there are unintended outcomes, and whether the program goals are appropriate and useful.Policy analysis is a technique used in public administration to enable civil servants, activists, and others to examine and evaluate the available options to implement the goals of laws and elected officials.\n\n\n== Subfields of political science ==\nMany political scientists conduct research in one of four areas, described below:\nPolitical Philosophy: Concerned with the foundations of political community and institutions, while focusing on human nature and the moral purposes of political association.\nComparative Politics: Compares contemporary political systems and discovers general laws and theories.\nInternational Relations: Concerned with developing an understanding of why states and non-state international actors interact.\nPolitical Methodology: Studies the philosophical bases of social science, political science, empirical research design and analysis.Some political science departments also classify methodology as well as scholarship on the domestic politics of a particular country as distinct fields. In the United States, American politics is often treated as a separate subfield. In contrast to this traditional classification, some academic departments organize scholarship into thematic categories, including political philosophy, political behaviour (including public opinion, collective action, and identity), and political institutions (including legislatures and international organizations). Political science conferences and journals often emphasize scholarship in more specific categories. The American Political Science Association, for example, has 42 organized sections that address various methods and topics of political inquiry.\n\n\n== Research methods ==\n\nPolitical science is methodologically diverse; political scientists approach the study of politics from a host of different ontological orientations and with a variety of different tools. Because political science is essentially a study of human behaviour, in all aspects of politics, observations in controlled environments are often challenging to reproduce or duplicate, though experimental methods are increasingly common (see experimental political science). Citing this difficulty, former American Political Science Association President Lawrence Lowell once said "We are limited by the impossibility of experiment. Politics is an observational, not an experimental science." Because of this, political scientists have historically observed political elites, institutions, and individual or group behaviour in order to identify patterns, draw generalizations, and build theories of politics.\nLike all social sciences, political science faces the difficulty of observing human actors that can only be partially observed and who have the capacity for making conscious choices, unlike other subjects such as non-human organisms in biology or inanimate objects as in physics. Despite the complexities, contemporary political science has progressed by adopting a variety of methods and theoretical approaches to understanding politics, and methodological pluralism is a defining feature of contemporary political science.\nEmpirical political science methods include the use of field experiments, surveys and survey experiments, case studies, process tracing, historical and institutional analysis, ethnography, participant observation, and interview research.Political scientists also use and develop theoretical tools like game theory and agent-based models to study a host of political systems and situations.Political theorists approach theories of political phenomena with a similar diversity of positions and tools, including feminist political theory, historical analysis associated with the Cambridge school, and Straussian approaches.\nPolitical science may overlap with topics of study that are the traditional focuses of other social sciences—for example, when sociological norms or psychological biases are connected to political phenomena. In these cases, political science may either inherit their methods of study or develop a contrasting approach. For example, Lisa Wedeen has argued that political science\'s approach to the idea of culture, originating with Gabriel Almond and Sidney Verba and exemplified by authors like Samuel P. Huntington, could benefit from aligning more closely with the study of culture in anthropology. In turn, methodologies that are developed within political science may influence how researchers in other fields, like public health, conceive of and approach political processes and policies.\n\n\n== Education ==\nPolitical science, possibly like the social sciences as a whole, can be described "as a discipline lives on the fault line between the \'two cultures\' in the academy, the sciences and the humanities." Thus, in some American colleges where there is no separate school or college of arts and sciences per se, political science may be a separate department housed as part of a division or school of humanities or liberal arts. Whereas classical political philosophy is primarily defined by a concern for Hellenic and Enlightenment thought, political scientists are also marked by a great concern for "modernity" and the contemporary nation state, along with the study of classical thought, and as such share more terminology with sociologists (e.g., structure and agency).\nMost United States colleges and universities offer BA programs in political science. MA or MAT and PhD or EdD programs are common at larger universities. The term political science is more popular in North America than elsewhere; other institutions, especially those outside the United States, see political science as part of a broader discipline of political studies, politics, or government. While political science implies the use of the scientific method, political studies implies a broader approach, although the naming of degree courses does not necessarily reflect their content. Separate programs (often professional degrees) in international relations and public policy are not uncommon at both the undergraduate and postgraduate levels. Master\'s-level programs in public administration are professional degrees covering public policy along with other applied subjects; they are often seen as more linked to politics than any other discipline, which may be reflected by being housed in that department.The national honor society for college and university students of government and politics in the United States is Pi Sigma Alpha.\n\n\n== Writing in political science ==\nThere are different genres of writings in political sciences; including but not limited to:\nArgument essays and Research papers\nPolitical theory writing\nResponses to articles, texts, events thoughts and reflective papersThe most common piece of writing in political sciences are research papers, which investigate an original research question.\n\n\n== See also ==\n\nComparative politics\nHistory of political science\nInternational relations\nOutline of political science – structured list of political topics, arranged by subject area\nIndex of politics articles – alphabetical list of political subjects\nPolitical history of the world\nPolitical lists – lists of political topics\nPolitical philosophy\n\n\n== References ==\n\n\n== Further reading ==\nThe Evolution of Political Science (November 2006). APSR Centennial Volume of American Political Science Review. Apsanet. 4 February 2009.\nEuropean Political Processes: Essays and Readings (1968). [Compiled and] ed., with original essays, by Henry S. Albinski [and] Lawrence K. Pettit. Boston: Allyn & Bacon. vii, 448 p.\nOxford Handbooks of Political Science\nAbbott, Kenneth W., and Duncan Snidal. "Hard and soft law in international governance." International organization 54.3 (2000): 421–456.\nAtchison, Amy L, editor. Political Science Is for Everybody : An Introduction to Political Science. University of Toronto Press, 2021.\nBadie, Bertrand, et al. International Encyclopedia of Political Science. SAGE, 2011.\nBlatt, Jessica. Race and the Making of American Political Science. University of Pennsylvania Press, 2018.\nBleich, Erik. "What is Islamophobia and how much is there? Theorizing and measuring an emerging comparative concept." American behavioral scientist 55.12 (2011): 1581–1600.\nBornschier, V. (1996). Western society in transition. New Brunswick, N.J.: Transaction.\nBornschier, V. (2005). Culture and politics in economic development. London: Routledge (Routledge frontiers of political economy, 67).\nBornschier, V. (2016). Hegemonic decline, West European unification, and the future structure of the core. Journal of World-Systems Research, 1, 69–96. https://doi.org/10.5195/jwsr.1995.42\nBornschier, V., & Chase-Dunn, C. K. (1985) Transnational corporations and underdevelopment. New York: Praeger.\nBrand, Ulrich, and Markus Wissen. "Crisis and continuity of capitalist society-nature relationships: The imperial mode of living and the limits to environmental governance." Review of International Political Economy 20.4 (2013): 687–711.\nBrand, Ulrich, and Markus Wissen. The limits to capitalist nature: Theorizing and overcoming the imperial mode of living. Rowman & Littlefield, 2018.\nBrand, Ulrich. "Green economy–the next oxymoron? No lessons learned from failures of implementing sustainable development." GAIA-Ecological Perspectives for Science and Society 21.1 (2012): 28–32.\nCaramani, Daniele, editor. Comparative Politics. Fifth ed., Oxford University Press, 2020.\nElsenhans, H. (2011). The rise and demise of the capitalist world system. Leipzig: Leipziger Universitätsverlag.\nElsenhans, H. (2014). Saving capitalism from the capitalists: world capitalism and global history. Los Angeles: Sage.\nElsenhans, H. (2016). Hartmut Elsenhans and a critique of capitalism: conversations on theory and policy implications. Edited by N. Wilcock and C. Scholz. Houndmills, Basingstoke, Hampshire: Palgrave Macmillan. doi: 10.1007/978-1-137-56464-1.\nElsenhans, H. (2021). Development, capitalism, and rent: the political economy of Hartmut Elsenhans. Edited by H. Warnecke-Berger. Cham, Switzerland: Palgrave Macmillan. doi: 10.1007/978-3-030-62605-1.\nElsenhans, H., & Babones, S. (2020). BRICS or Bust? Stanford University Press.\nGerardo L. Munck and Richard Snyder, eds. (2007) Passion, Craft, and Method in Comparative Politics. Baltimore, MD: Johns Hopkins University Press.\nGoodin, R.E.; Klingemann, Hans-Dieter (1996). A New Handbook of Political Science. Oxford and New York: Oxford University Press. ISBN 0-19-829471-9.\nGoodin, Robert E, editor. The Oxford Handbook of Political Science. Oxford University Press, 2011.\nGrinin, L., Korotayev, A. and Tausch A. (2016) Economic Cycles, Crises, and the Global Periphery. Springer International Publishing, Heidelberg, New York, Dordrecht, London, ISBN 978-3-319-17780-9;\nHayek, F. A. (1960). The constitution of liberty. Chicago: University of Chicago Press.\nHochschild, Jennifer L. Race and Class in Political Science. Michigan Journal of Race and Law. 2005;11 (1) :99-114.\nInglehart, Ronald F. Religion\'s sudden decline: what\'s causing it, and what comes next?. Oxford University Press, USA, 2021.\nInglehart, Ronald, Pippa Norris, and Inglehart Ronald. Rising tide: Gender equality and cultural change around the world. Cambridge University Press, 2003.\nKatznelson, Ira, et al. Political Science: The State of the Discipline. W.W. Norton, 2002.\nKellstedt, Paul M, and Guy D Whitten. The Fundamentals of Political Science Research. Third edition., Third ed., Cambridge University Press, 2018.\nKohler, Gernot, et al. Globalization : Critical Perspectives. Nova Science Publishers, New York, 2003. With contributions by Samir Amin, Immanuel Wallerstein, Christopher Chase-Dunn, Kimmo Kiljunen, Andre Gunder Frank, et al.\nKlingemann, Hans-Dieter, ed. (2007) The State of Political Science in Western Europe. Opladen: Barbara Budrich Publishers. ISBN 978-3-86649-045-1.\nLowndes, Vivien, et al., editors. Theory and Methods in Political Science. Fourth ed., Palgrave Macmillan, 2018.\nNoel, Hans (2010-10-14 | DOI https://doi.org/10.2202/1540-8884.1393) "Ten Things Political Scientists Know that You Don’t" The Forum: Vol. 8: Iss. 3, Article 12. de Gruyter.\nMorlino, Leonardo, et al. Political Science : A Global Perspective. Sage, 2017.\nNorris, Pippa. "Cancel Culture: Myth or Reality?." Political Studies (2021): 00323217211037023.\nNorris, Pippa. Democratic deficit: Critical citizens revisited. Cambridge University Press, 2011.\nRoskin, M.; Cord, R.L.; Medeiros, J.A.; Jones, W.S. (2007). Political Science: An Introduction. 10th ed. New York: Pearson Prentice Hall. ISBN 978-0-13-242575-9.\nRosenberger, Sieglinde, and Birgit Sauer. Politics, Religion and Gender : Framing and Regulating the Veil. Routledge, 2012.\nSchram, S.F.; Caterino, B., eds. (2006). Making Political Science Matter: Debating Knowledge, Research, and Method. New York and London: New York University Press. Google Books 4 February 2009.\nSenghaas, D. (1985). The European experience: a historical critique of development theory. Leamington Spa, Warwickshire: Berg.\nSenghaas, D. (2013). Dieter Senghaas: pioneer of peace and development research. Berlin: Springer (Springerbriefs on pioneers in science and practice, 6). doi: 10.1007/978-3-642-34114-4.\nShively, W. Phillips. Power & Choice : An Introduction to Political Science. Fifteenth ed., Rowman & Littlefield, 2019.\nSolomon, Hussein. Islamic State and the Coming Global Confrontation. Palgrave Macmillan, 2016.\nTausch, A.; Prager, F. (1993). Towards a Socio-Liberal Theory of World Development. Basingstoke: Macmillan; New York: St. Martin\'s Press and Springer.\nTausch, Arno (2015). The political algebra of global value change. General models and implications for the Muslim world. With Almas Heshmati and Hichem Karoui (1st ed.). Nova Science Publishers, New York. ISBN 978-1629488998.\nTausch, Arno, For a globally visible political science in the 21st Century. Bibliometric analyses and strategic consequences (October 26, 2021). Available at SSRN: https://ssrn.com/abstract= Archived 27 March 2009 at the Wayback Machine\nTaylor, C. L., & Russett, B. M. (Eds.). (2020). Karl W. Deutsch: Pioneer in the Theory of International Relations. Springer.\nVan Evera, Stephen. Guide to Methods for Students of Political Science. Cornell University Press, 1997.\nZippelius, Reinhold (2003). Geschichte der Staatsideen (History of political Ideas), 10th ed. Munich: C.H. Beck. ISBN 3-406-49494-3.\nZippelius, Reinhold (2010). Allgemeine Staatslehre, Politikwissenschaft (Political Science),16th ed. Munich: C.H. Beck. ISBN 978-3-406-60342-6.\n\n\n== External links ==\n\n\n=== Professional organizations ===\nEuropean Consortium for Political Research\nInstitute for Comparative Research in Human and Social Sciences (ICR) in Japan\nInternational Association for Political Science Students\nInternational Political Science Association\nInternational Studies Association\nMidwest Political Science Association\nPolitical Studies Association of the UK\nSouthern Political Science Association\n\n\n=== Further reading ===\nIPSAPortal: Top 300 websites for Political Science\nObservatory of International Research (OOIR): Latest Papers and Trends in Political Science\nPROL: Political Science Research Online (prepublished research)\n\n\n=== Library guides ===\nLibrary. "Political Science". Research Guides. United States: University of Michigan. Archived from the original on 7 July 2014. Retrieved 15 February 2014.\nBodleian Libraries. "Political Science". LibGuides. United Kingdom: University of Oxford. Archived from the original on 18 February 2014. Retrieved 15 February 2014.\nLibrary. "Politics Research Guide". LibGuides. New Jersey, United States: Princeton University. Archived from the original on 23 July 2014. Retrieved 15 February 2014.\nLibraries. "Political Science". Research Guides. New York, United States: Syracuse University. Archived from the original on 8 July 2014. Retrieved 15 February 2014.\nUniversity Libraries. "Political Science". Research Guides. United States: Texas A&M University. Archived from the original on 21 October 2014. Retrieved 15 February 2014.', 'America is a rock band that was formed in London in 1970 by Dewey Bunnell, Dan Peek, and Gerry Beckley. The trio met as sons of US Air Force personnel stationed in London, where they began performing live. Achieving significant popularity in the 1970s, the trio was famous for its close vocal harmonies and light acoustic folk rock sound. The band released a string of hit albums and singles, many of which found airplay on pop/soft rock stations.\nThe band came together shortly after the members\' graduation from high school in the late 1960s. In 1970, Peek joined the band, and they signed a record deal with Warner Bros. The following year, they released their self-titled debut album, which included the transatlantic hits "A Horse with No Name" and "I Need You". Their second album, Homecoming (1972), included the single "Ventura Highway". Over the next several years, the band continued to release hit songs, including “Muskrat Love” on Hat Trick (1973), "Tin Man" and "Lonely People" on Holiday (1974), and "Sister Golden Hair" and "Daisy Jane" on their 1975 record Hearts. It was also in 1975 when America released History: America\'s Greatest Hits, a compilation of hit singles, which was certified multi-platinum in the United States and Australia. Peek left the group in 1977 and their commercial fortunes declined, though they returned to the top 10 in 1982 with the single "You Can Do Magic". The band\'s final Top 40 hit was "The Border", which reached no. 33 on the Billboard Hot 100 in 1983. The group continues to record material and tour regularly. Its 2007 album Here & Now was a collaboration with a new generation of musicians who have credited the band as an influence.\nAmerica won a Grammy Award for Best New Artist and were nominated for Best Pop Vocal Group at the 15th Annual Grammy Awards in 1973. The group was inducted into the Vocal Group Hall of Fame in 2006 and received a star on the Hollywood Walk of Fame in 2012.\n\n\n== History ==\n\n\n=== Early success (1970–1973) ===\n\nWhile their fathers were stationed at the United States Air Force base at RAF South Ruislip near London in the mid-1960s, Beckley, Bunnell and Peek attended London Central High School at Bushey Hall, where they met while playing in two different bands.\nPeek left for the United States for a failed attempt at college during 1969. Soon after his return to the UK the following year, the three began making music together. Starting out with borrowed acoustic guitars, they developed a style that incorporated three-part vocal harmony with the style of contemporary folk-rock acts such as Crosby, Stills & Nash.\nEventually, the trio dubbed itself America, inspired by the Americana jukebox in their local mess hall and chose it because they did not want anyone to think they were British musicians trying to sound American. They played their first gigs in the London area, including some highlights at the Roundhouse in London\'s Chalk Farm district. They were eventually taken on by producer Ian Samwell, best known for writing Cliff Richard\'s 1958 breakthrough hit "Move It", and his partner Jeff Dexter, and through their efforts, they were eventually contracted to Kinney Records (UK) in March 1971 by Ian Ralfini and assigned to the UK Warner Bros. label.\nTheir first album, America, (1971) was recorded at Trident Studios in London and produced by Samwell and Dexter, who became the trio\'s manager. Dexter also gave the band their first major gig, 20 December 1970, at Implosion at the Roundhouse, Chalk Farm, as the opening act for The Who, Elton John, Patto and the Chalk Farm Salvation Army Band and Choir for a Christmas charity event. Although the trio initially planned to record the album in a similar manner to The Beatles\' Sgt. Pepper\'s Lonely Hearts Club Band, Samwell convinced them to perfect their acoustic style, instead.\nThe debut album America was released in late December 1971 to only moderate success, although it sold well in the Netherlands, where Dexter had taken them as a training ground to practice their craft. Samwell and Dexter subsequently brought the trio to Morgan Studios to record several additional songs. One of them was a Bunnell composition called "Desert Song", which Dexter previously demonstrated during studio rehearsals in Puddletown, Dorset, at the home of Arthur Brown. The song had its public debut at the Harrogate Festival, four days later, to great audience response. After several performances and a TV show, it was retitled "A Horse with No Name". The song became a major worldwide hit in early 1972. It sold over one million copies, and was awarded a gold disc by the RIAA in March 1972. America\'s debut album was released in the U.S. that same month with the hit song added and quickly went platinum. The album resulted in a second major chart success with Beckley\'s "I Need You", which peaked at number 9 on the US charts.After their initial success, the trio played a series of North American club and college dates in early 1972 and decided to dismiss Samwell and Dexter and relocate to Los Angeles, California, signing with the David Geffen/Elliot Roberts stable at Lookout Management. By 1973, the band had left Lookout to go with John Hartmann and Harlan Goodman after the latter two had broken away from Geffen/Roberts to set up their own management firm.The recording of a second album was delayed by the relocation, as well as by an injury to Peek\'s arm. Deciding not to replace Samwell, the group opted to produce the album themselves. The trio began their move away from a mainly acoustic style to a more rock music-oriented style with the help of Hal Blaine on drums and Joe Osborn on bass. With Peek playing lead electric guitar on more tracks, the group expanded from an acoustic trio to embrace a fuller live sound, adding Dave Atwood (who had played as a session musician on their debut album) on drums and David Dickey (formerly of the group Captain) on bass in late 1972. But their next tour was delayed until January 1973 after Peek fell ill with hepatitis. On March 11th 1973, Atwood had been replaced by Dickey\'s former Captain bandmate, Willie Leacox.\n\n \nAmerica\'s second album, Homecoming, was released in November 1972. Awarded a gold disc in December 1972, the album\'s million sales figure was confirmed by the RIAA in 1975. The group reached the top 10 again with Bunnell\'s "Ventura Highway". Based on their first two albums, the group won a Grammy Award for Best New Artist of 1972.\nThe group\'s output grew increasingly ambitious. Their third offering, Hat Trick, was released in October 1973 following several months of recording at the Record Plant Studios in Los Angeles. Again self-produced, the album featured strings, harmonicas, an eight-minute title track, and tap dancing. Beckley, Bunnell and Peek were once again joined by Blaine on drums, while Osborn was replaced by their touring bassist, David Dickey. The album was not as successful as Homecoming, featuring only one modestly successful single, "Muskrat Love" (number 67 in the US), penned by Texas folk singer Willis Alan Ramsey. A Captain & Tennille cover of the song reached the top 10 in late 1976.\n\n\n=== George Martin years (1974–1979) ===\nAfter the disappointing commercial performance of Hat Trick, America chose to enlist an outside producer for their next album. They were able to secure the services of producer George Martin and recording engineer Geoff Emerick, who played a major role in shaping the sound of the Beatles. Sessions took place at AIR Studios in London.\nThe resulting album, Holiday, was released in June 1974 (by this time the group had consciously begun naming their albums with titles starting with the letter H). With Martin\'s guidance, the album\'s style was very different from America\'s first three efforts, as he enhanced America\'s acoustic sound with strings and brass.\nDuring an early 1975 tour of Europe, bassist Calvin "Fuzzy" Samuels (formerly of Crosby, Stills, Nash & Young and Manassas) was called to fill in for Dickey, who was not available. Samuels also appeared live with the group on the German TV program Musikladen.\nThe trio soon found themselves in the top 10 once again with the first single from Holiday, the Bunnell-penned "Tin Man", which reached number four, featuring cryptic lyrics set to a Wizard of Oz theme. "Lonely People" (written by Dan Peek) followed Tin Man into the top 10 in early 1975, becoming Dan Peek\'s only credited song to reach that high on Billboard, peaking at number five.Martin worked with the trio again for their next LP, Hearts, recorded in Sausalito, California, and released in March 1975. America scored its second chart-topping success with Beckley\'s "Sister Golden Hair" in mid-1975, a song that featured a memorable opening guitar riff admittedly inspired by George Harrison\'s "My Sweet Lord" and frank relationship lyrics inspired by Jackson Browne. The follow-up single, Beckley\'s ballad "Daisy Jane", also scored among the top 20 shortly after. Peek\'s reggae-influenced Woman Tonight was a third success (No. 44 in the US) from the album towards the end of the year.Warner Bros. released a compilation of America\'s best-known tracks in December 1975, History: America\'s Greatest Hits, which went platinum. Martin, who produced the album, remixed those tracks, which were culled from the group\'s first three albums.During early 1976, the group recorded its sixth studio album at Caribou Ranch near Nederland, Colorado, inspiring the album\'s title, Hideaway, which Martin produced. Released in April 1976, the album\'s two singles, "Today\'s the Day" and "Amber Cascades", managed to reach Nos. 23 and 75, respectively, on the Billboard pop chart. The two singles hit number one and 17, respectively, on the Billboard adult contemporary chart. Songs such as "Jet Boy Blue" and "Don\'t Let It Get You Down" were programmed on FM stations.\nMartin\'s implementation of more complex instrumentation on America\'s albums proved somewhat overwhelming to the band on stage, often compelling them to switch from instrument to instrument during songs. For their 1976 tour, the group expanded their stage line-up to include Jim Calire on keyboards and sax and Tom Walsh on percussion, so they could more comfortably perform Martin\'s arrangements.Martin and the trio went to Hawaii during late 1976 to work on the group\'s seventh studio album, which was recorded in a beach house on the island of Kauai. The album, Harbor, released in February 1977, continued the trend of decreasing sales for the group. It was their first album to fail to score either platinum or gold, and none of its three singles charted.\nIn May 1977, Dan Peek left the band.  In his 2004 autobiography, An American Band, Peek states that he was voted out after missing a tour rehearsal but Bunnell later denied this was the case, saying that the decision to leave had been Peek\'s, after he recently had renewed his Christian faith following years of recreational drug use and had begun to seek a different artistic direction from Beckley or Bunnell. Nevertheless, Peek goes on to say in his book that he takes full blame for the group\'s fracturing.\nPeek contracted with Pat Boone\'s Lamb & Lion Records and issued his first solo album, All Things Are Possible, in 1978. The album, produced by Chris Christian, was successful and Peek became a pioneering artist in the emerging Christian popular music genre. The title track entered the Billboard pop charts in early 1979, peaking at No. 78.Meanwhile, Beckley and Bunnell decided to continue as America, ending their contract with Warner Bros. with the release of their first concert LP, Live, during October 1977. Recorded at the Greek Theater in Los Angeles, the performance featured a backing orchestra conducted by Elmer Bernstein. The concert was recorded shortly after Peek left the group. The album was only mildly successful on the popular charts; whereas all of their previous albums, even Harbor, had at least made the top 30, Live just barely made it onto the album chart, peaking at No. 129.\n\n\n=== Capitol years (1979–1985) ===\nAfter more than two years without new studio material, Beckley and Bunnell presented the group\'s new style with a cover of The Mamas & the Papas\' "California Dreamin\'" in March 1979. It was featured on the soundtrack for the 1979 movie California Dreaming. Although the movie was unsuccessful and the soundtrack was issued by an obscure distributor known as American International, the single reached number 56 on the charts.\nAmerica\'s first studio album without Peek, Silent Letter, was released in June 1979 on their new label, Capitol Records. The album, once again produced by George Martin, was recorded in Montserrat in the West Indies with the members of the live band: David Dickey, Willie Leacox, Michael Woods (their former roadie, who joined their touring band in late 1977 on lead guitar), Jim Calire and Tom Walsh. The group began to use songs from other songwriters as they sought to increase their commercial success. The album scored no higher than number 110 on the charts, leading Bunnell sarcastically to dub the album Silent Record. During the latter part of 1979, Calire and Walsh were dropped from the on-stage line-up. Session bassist Bryan Garafalo replaced Dickey in 1980 and Bradley Palmer took over from Garafalo in 1981.\nAmerica continued to evolve as the 1980s began. For their next album, Alibi, released in August 1980, Beckley and Bunnell sought fresh personnel in the form of producers Matthew McCauley and Fred Mollin. They also employed players from the West Coast, such as the Eagles\' Timothy B. Schmit, Leland Sklar and Steve Lukather, to help improve their sound. Alibi eschewed the strings and brass of a typical George Martin project in favour of a more popular-rock style. It also became the third studio album in a row without a successful single in the United States, although Beckley\'s "Survival" scored the top of the charts in Italy. The album\'s sales peaked at number 142.\nAmerica\'s next album, View from the Ground, released in July 1982, had the group finally score another commercial success. The album, recorded under the working title Two Car Garage, featured a number of songs produced by the duo themselves. As with Alibi (1980), Beckley and Bunnell brought in a number of high-profile musicians, including the Beach Boys\' Carl Wilson, Toto\'s Jeff Porcaro, Christopher Cross and Dean Parks. Former Argent guitarist Russ Ballard, though, had the greatest effect on the group\'s fortunes. Ballard produced and played all of the instruments and sang most of the background vocals on a song he crafted especially for the band, called "You Can Do Magic". The song rose quickly through the pop charts and scored as high as number eight on the Billboard pop-singles chart for a number of weeks during October 1982, the band\'s first major success in seven years. Following "Magic" was the single "Right Before Your Eyes". Written by Ian Thomas (brother of comedian Dave Thomas of Strange Brew fame), and produced by Bobby Colomby, the single barely missed a spot in the top 40 during early 1983. Although View from the Ground failed to achieve gold-rated sales, it scored as high as number 41 on the album charts, a significant improvement over the previous few releases.\nHaving had success with Ballard, Beckley and Bunnell asked the former Argent performer to produce their next album, Your Move, in its entirety. In the end, Ballard wrote most of the songs and performed most of the instruments in addition to his production duties. For the most part, Beckley and Bunnell were singers on an album that Ballard had crafted for them, although they did contribute some of their own material. On one track, Bunnell decided to rewrite Ballard\'s lyrics, and the successful song "The Border" was the result. Set to the backing of the Royal Philharmonic Orchestra and the saxophone work of Raphael Ravenscroft, the single scored number 33 on the charts in August 1983. "The Border" was much more successful on the adult contemporary charts, where it scored number four (even bettering "You Can Do Magic"). It also made number 24 on the Dutch top 40. A second single, Ballard\'s "Cast the Spirit", failed to chart. The album itself, released in June 1983, was reasonably successful at number 81, but something of a disappointment, when compared to its predecessor.\nAmerica\'s work was also featured on several soundtracks during this period. Beckley and Bunnell provided vocals to several Jimmy Webb compositions for the film The Last Unicorn in 1982. The soundtrack became popular in Germany and the group frequently plays its title track when touring in that country. America also recorded "Love Comes Without Warning" for the 1984 Steve Martin comedy The Lonely Guy.\nDan Peek emerged from several years of musical obscurity during May 1984, releasing his second solo Christian album, Doer of the Word, on Home Sweet Home Records. Once again produced by Chris Christian, the album\'s title track featured Beckley on backing vocals. Peek issued two more solo albums over the next few years: Electro Voice (1986) and Crossover (1987).\nMeanwhile, America opted for a decidedly different style from their previous offerings for their 12th studio album, Perspective, released in September 1984. Ballard was out and synthesizers and drum machines were in. Several different producers, including Richie Zito, Matthew McCauley (who had already produced the aforementioned track "Love Comes Without Warning" that appeared earlier that year in the film The Lonely Guy) and Richard James Burgess, helped create an electronic popular style that was very common during the 1980s but drastically different from America\'s usual style. "Special Girl", the album\'s first single, was culled from hired songwriters and failed to make the charts. The next single, "Can\'t Fall Asleep to a Lullaby", was co-written by Bunnell, Journey\'s Steve Perry, Robert Haimer, and Bill Mumy, the latter of Lost in Space and Babylon 5 fame. Although neither track was played on popular radio, both did achieve minor success on the adult contemporary charts. The album peaked at number 185 during a three-week stint on the charts in October 1984.\nTheir mainstream commercial success over, Beckley and Bunnell ended their Capitol contract with In Concert, released in July 1985. The album was recorded at the Arlington Theater in Santa Barbara, California on 1 June 1985. In Concert became the first America album to miss the charts entirely.\n\n\n=== Return to basics (1985–1998) ===\nBeckley and Bunnell spent the latter half of the 1980s focusing on their live show, performing well over 100 times a year around the world. While America remained a hot ticket on the touring circuit, they were unable to land a recording contract in the years after they left the Capitol label.\nBy the early 1990s, the development of compact discs led to the reissuing of many older popular albums, providing acts such as America with revived sales. During 1991, America was able to offer four new tracks as part of a collection issued by Rhino Records called Encore: More Greatest Hits, which was designed to complement the group\'s original 1975 retrospective.\nAmerica\'s resurgence caught the eye of Chip Davis of American Gramaphone Records, who signed the group to his label. In May 1994, America released its first new studio album in a decade, Hourglass. Produced primarily by Beckley and Bunnell, with help from Hank Linderman and Steve Levine, the album featured an eclectic group of songs. Despite garnering generally positive reviews, the album was a commercial failure.\nDuring 1995, Beckley delivered his debut solo album. Entitled Van Go Gan, the album experimented with various styles and sounds. Comedian Phil Hartman (who during his career as a graphic artist had designed several America album covers) was featured as the voice of a televangelist preacher on Playing God. Although it was named as one of the top-10 music CDs of the year in Japan in 1995, the album was not released outside Japan until four years later.America fans were also treated to a concert album in 1995. Released by the King Biscuit Flower Hour Records, Inc., the concert was actually taken from a 1982 instalment of the King Biscuit Flower Hour radio show. Known as In Concert (not to be confused with the 1985 Capitol release of the same name), King Biscuit experienced modest success with the album (though America themselves did not; it failed to break the charts).\nThis success resulted in a new record deal with King Biscuit\'s subsidiary label, Oxygen Records. After rumours that Steely Dan producer Gary Katz would produce the project came and went, the album eventually reached stores in September 1998. The new album, entitled Human Nature after the name of Beckley\'s home recording studio, was accompanied by a modest commercial blitz. The first single, Beckley\'s From a Moving Train, featured a strongly acoustic style. The track received considerable airplay and moderate success in adult contemporary formats. Reports claimed that the song was a major success in the popular charts in Spain. A second attempt at a single in Wednesday Morning was somewhat less successful. The album failed to garner the sales that Oxygen was expecting and America was once again without a record deal.\n\n\n=== New millennium (1999–2006) ===\nThe next few years had the group\'s catalogue expand with a number of side projects, reissues of older albums on CD, and several major retrospective releases. In July 2000 Rhino released Highway: 30 Years of America, a three-CD box set which included 64 remastered tracks spanning the group\'s career. Included were a handful of alternative mixes and demos such as an early take of a stripped-down Ventura Highway.\nA year later, in August 2001, Rhino released a trimmed-down single disc compilation, The Complete Greatest Hits, which assembled all of the group\'s 17 charting Billboard singles. The disc also included two newly recorded songs, World of Light and Paradise. Peaking at number 152 on the Billboard album charts in October 2001, The Complete Greatest Hits was America\'s first charting album since Perspective in 1984.\nOn the solo front, in February 2000, Beckley released Go Man Go, an album of remixed tracks from Van Go Gan. The original Van Go Gan finally had a domestic release that July with bonus tracks. June was the roll-out of another Beckley side project, Like A Brother, recorded with Robert Lamm and Carl Wilson under the name Beckley-Lamm-Wilson. Dan Peek resurfaced in 1999 with a new website and his first solo release in many years, Bodden Town.\nAs part of a contemporary trend of recycling oldies recordings to create new hits, Janet Jackson\'s 2001 single "Someone to Call My Lover" sampled the Ventura Highway guitar riff and rose to number three on the Billboard pop charts.\nIn October 2002 the group released its first Christmas album, Holiday Harmony. Produced by Andrew Gold, the album received positive reviews for its imaginative blending of elements of classic America tunes into familiar holiday standards. Included were three new tracks, including a Bunnell-penned ode to Ventura Highway called Christmas in California, featuring Beckley on lead vocals. One month later, America released a live album, The Grand Cayman Concert. Recorded the previous April in the Cayman Islands, the concert featured just Beckley and Bunnell on acoustic guitars, a throwback to the earliest days of their career. Included were their most familiar songs along with a few that were almost never performed live, such as Wind Wave and Pigeon Song. Both albums failed to chart.\nAfter this, the band ceased recording and concentrated on their consistently lucrative touring schedule.\nIn early 2003, Bradley Palmer left the touring band after 22 years and was replaced, first by Chas Frichtell, then by Trent Stroh, until Richard Campbell (formerly toured with Three Dog Night, Natalie Cole and Dave Mason) came in permanently.\nRecord labels occasionally offered new DVDs, such as a re-release of America\'s 1979 concert film, Live in Central Park, a 2004 concert at the Sydney Opera House and a 2005 show at the Ventura Concert Theater joined with Stephen Bishop and Andrew Gold directed by Sheldon Osmond. Also in 2005, America appeared on the PBS concert series Soundstage with long-time friend Christopher Cross and a guest appearance by rock photographer Henry Diltz on banjo.\nIn April 2006 after a few solo concerts, Beckley released his third solo album, Horizontal Fall, which was largely ignored by both critics and buyers. His 2011 follow-up, Unfortunate Casino, met a similar fate.\n\n\n=== Recent activity (2006–present) ===\nAs the second half of the first decade of the 2000s began, the group remained very much active and popular in the nostalgia concert circuit. Though the group had occasionally issued new material on minor labels, their offerings had been largely ignored by the greater commercial music industry and record-buying public.\nHowever, a fateful connection provided a sudden and unexpected change in fortune for the group. Around 2005, Beckley began correspondence with Adam Schlesinger of the independent rock music group Fountains of Wayne. Beckley had been a fan of the 2003 Fountains of Wayne album Welcome Interstate Managers, and Schlesinger turned out to be a fan of America\'s work. The exchange of songs between the two resulted in them recording a few tracks together. The recordings came to the attention of SonyBMG\'s new Burgundy Records label, which was impressed both by the quality of the material and by the possibility of pairing America with other independent artists. The company contracted America to record a new album with Schlesinger and his musical partner, James Iha, formerly of The Smashing Pumpkins, at the production helm. Entitled Here & Now (2007), it would be America\'s first major-label studio album since Perspective in 1984.\nThe recording sessions at Stratosphere Sound in New York City, which ran through July, attracted a number of notable guest musicians, including Ryan Adams, Ben Kweller, Stephen Bishop, Rusty Young and members of the groups Nada Surf and My Morning Jacket.\nIn an effort to aim the album toward both younger and older audiences, the label decided to bundle the new album with a second disc comprising live performances of every track from History: America\'s Greatest Hits, previously recorded at XM Radio as part of XM\'s Then Again...Live series, recorded with longtime America drummer Willie Leacox, guitarist Michael Woods and bassist Richard Campbell. In the run-up to the album\'s scheduled release on 16 January 2007, America attracted publicity unknown to it since the early 1980s. The release itself was well received by critics, and Here & Now went all the way to number 52 in the Billboard charts.\n\nIn addition to receiving growing support from a new generation of musicians, America finally began to receive acclamation from the entertainment industry. In 2006 America was inducted into the Vocal Group Hall of Fame. And on 6 February 2012 the group was given a star on the Hollywood Walk of Fame for their contributions to music at 6752 Hollywood Boulevard. The band continued to perform over 100 shows per year.\nAmerica\'s follow-up to Here & Now (2007) was released on 26 July 2011. Entitled Back Pages, the album was a collection of twelve tracks covering songs from artists ranging from Bob Dylan and Joni Mitchell to Adam Schlesinger and the Gin Blossoms. Released on the E1 Music label, the album was produced by Fred Mollin, who had originally worked with America 31 years before on Alibi. The album was recorded in Nashville, Tennessee, with the help of a number of studio musicians. The release of Back Pages was briefly overshadowed by the publicity surrounding the sudden death of founding member Dan Peek on 24 July 2011.\nIn February 2014, lead guitarist and background vocalist Michael Woods (Woodz), who had been with the touring band since the fall of 1977, announced his retirement from the band due to ill health. His replacement was Nashville musician Bill Worrell.\nIn March 2014, long-time Beach Boys and Brian Wilson vocalist/guitarist Jeff Foskett subbed for Beckley at some concerts and long-time drummer Willie Leacox retired from the band in July 2014, after an almost 42-year tenure, and was replaced by former Reel Big Fish drummer Ryland Steen.\nIn November 2014, America recorded a live performance at Infinity Hall in Hartford, CT for Connecticut Public Television that was subsequently aired nationwide in June 2015, and afterwards streamed online. During late summer 2015, guitarist/keyboardist Andy Barr, from the group Cobra Starship, came in for Worrell, who had a broken wrist. After healing, Worrell returned to the group until leaving for a solo career in October 2016. Barr then joined America permanently, but left himself for a solo career and was replaced by Steve Fekete in 2018. Long time America bassist David Dickey died on 3 December 2016 at his home in Sweetwater, Texas.In May 2019, Gonzo Multimedia released a deluxe boxed set of America\'s 2018 show at the London Palladium titled "America Live at The Palladium" featuring their greatest hits. America cancelled a string of shows in March 2020 due to the COVID-19 pandemic.\n\n\n== Dan Peek ==\nFrom the time Dan Peek left the group in May 1977, and up until his death in July 2011, speculation abounded as to whether he could or would return to the fold. On Peek\'s 1978 solo debut album, All Things Are Possible, Beckley and Bunnell sang back-up vocals on the track Love Was Just Another Word. According to Peek and Bunnell, in June 1983, Peek even joined the group onstage to perform a few songs during a concert at the Greek Theater in Los Angeles. On Peek\'s 1984 follow-up album, Doer of the Word, Beckley provided prominent backing vocals on the title track. In November 1999, credible rumours began to spread, that unreleased demo recordings from the early 1980s featuring Beckley and Bunnell collaborating with Peek would be released on CD sometime in early 2000. No such recordings have been released to date.\nThe questions about a possible reunion of the original trio began not long after Peek left the group. When asked about the prospects for a reunion in the early 1980s, Beckley and Bunnell stated that they were happy for Peek in that he had found a new life and a new direction, but that it was unlikely there would be a reunion. "All things are possible, like [Dan] says", Beckley told radio host Lew Irwin in 1982, but "it just doesn\'t seem in the cards." Within a few years, however, Peek had begun to entertain just such thoughts publicly. "Like they said and like I said, all things are possible", Peek told interviewer Steve Orchard in 1985. "I really have my fingers crossed. I would love to get back together [with them] and do some things."\nAlthough Beckley and Bunnell had over the years become increasingly firm in their position, that a reunion with Peek was unlikely, and could in fact be counterproductive, record companies tried to persuade them to change their minds. Bunnell noted to Steve Orchard in 1998, that "[w]e had a few labels say that they would be interested in recording us if we would bring Dan back or if we could put together the original trio." Beckley and Bunnell chose to maintain their decision to remain a duo.\nIn 2000, Peek began posting a number of weekly episodes to his website relating to his experiences prior to and during his years in America. Peek raised a few eyebrows both for his candid discussion of his experiences with drugs and religion and for his observations of Beckley and Bunnell. Eventually, Peek compiled the material into a book entitled An American Band, which was released in late 2004.\nCertain sources have suggested erroneously that a reunion with Peek actually did occur. A Rolling Stone rock music discography book, printed during the mid-1990s, contained an apocryphal entry for America stating, that Dan Peek had reunited with Beckley and Bunnell for a tour in 1993 with the Beach Boys. This misinformation has been so widely disseminated, that the Australian rock journalist and historian Glenn A. Baker erroneously assumed this to be true in an interview question posed to Beckley and Bunnell on the Live at the Sydney Opera House DVD.\nFurthermore, during an interview airing on 7 June 2010 on the Steel Pier Radio Show with Ed Hurst airing on WIBG Radio, Peek was asked about the reunion prospects and more or less ruled them out. The last song Peek recorded was Kiss Me on the Waves (2011) with the Spanish band Etcetera, as guest singer. The song was written by Guillermo Albelo and included in the album Steps on the Water.\nContinuous speculations of Peek reuniting with America finally came to an end when Peek died in his home in Farmington, Missouri of fibrinous pericarditis on 24 July 2011, at the age of 60.\n\n\n== Personnel ==\nCurrent membersGerry Beckley – lead and backing vocals, keyboards, guitars, bass, harmonica (1970–present)\nDewey Bunnell – lead and backing vocals, guitars, percussion (1970–present)Former membersDan Peek – lead and backing vocals, guitars, bass, keyboards, harmonica (1970–1977; died 2011)Current touring musiciansRichard Campbell – bass, vocals (2003–present)\nRyland Steen – drums, percussion (2014–present)\nSteve Fekete - guitars, keyboards, backing vocals (2018–present)Former touring musiciansDavid Dickey – bass, backing vocals (1972–1980; died 2016)\nDavid Atwood – drums, percussion (1972–1973)\nWillie Leacox – drums, percussion (1973–2014; died 2022)\nCalvin "Fuzzy" Samuels – bass (1975; substitute for Dickey)\nJim Calire – keyboards, saxophone (1976–1979)\nTom Walsh – percussion (1976–1979)\nMichael Woods – guitars, keyboards, vocals (1977–2014)\nBryan Garofalo – bass (1980–1981)\nBradley Palmer – bass, vocals (1981–2003)\nTrent Stroh – bass, backing vocals (2003)\nChas Frichtell – bass, backing vocals (2003)\nBill Worrell – guitars, banjo, keyboards, backing vocals (2009-sub for Woods, 2014–2016)\nAndy Barr – guitars, banjo, keyboards, backing vocals (2016–2018)\n\n\n== Discography ==\n\n\n== References ==\n\n\n== External links ==\nOfficial website\nAmerica discography at Discogs\nAmerica at IMDb\nPhotos of America – Gerry and Dewey\nOfficial America page at Burgundy Records\nOfficial America fan page\nAmerica Blog page\nLive Concert Recording of America at the Blossom Music Center, Ohio on 5 September 1982', 'Omar bin Osama bin Mohammed bin \'Awad bin Laden (Arabic: عمر بن أسامة بن محمد بن عوض بن لادن, ʿUmar bin ʾUsāmah bin Muḥammad bin ʿAwaḍ bin Lādin; born March 1, 1981), better known as Omar bin Laden, is an Arabian artist, author, cultural ambassador, and businessman, and fourth-eldest son of Osama bin Laden, with his first wife and first cousin Najwa Ghanhem (see Bin Laden family). He has been living in Normandy, France for several years.Earlier inaccurate reports described Omar and his brother Abdallah bin Laden as nephews or cousins of Osama bin Laden.\n\n\n== Childhood ==\nBin Laden was born the grandson of Mohammed bin Awad bin Laden, the founder of one of the wealthiest non-royal families in Saudi Arabia, and the son of Osama bin Laden, whose partisan activities shaped his childhood. Bin Laden accompanied his father on his exile to Sudan from 1991 to 1996, and then to Afghanistan after that.He said that he trained in al-Qaeda camps beginning at the age of 14, but after training with al-Qaeda for six years and sharing a house with al-Qaeda\'s second-in-command Ayman al-Zawahiri, he left al-Qaeda in 2000 because he did not want to be associated with killing civilians and his father Osama did not object.In 2010, Omar bin Laden told ABC News that Osama had severely beaten him when he was a child for smiling too widely.\n\n\n== Post-9/11 ==\nBin Laden ran his own company in Jeddah prior to 2006 as a contractor and scrap metal dealer. Jeddah, a major city and important transit port for Saudi Arabia, is the site of the headquarters of the Saudi Binladen Group and has been reported to be "truly" ruled by Bakr bin Laden.\n\n\n=== Marriage to Zaina Mohamed Al-Sabah ===\nOmar bin Laden married Jane Felix-Browne, who also goes by the name Zaina Mohamed Al-Sabah, a parish councillor from Moulton, near Northwich in Cheshire in the United Kingdom, on September 15, 2006. The marriage was conducted in September 2006 in Islamic ceremonies in both Egypt and Saudi Arabia, after which the couple spent a few months together in Jeddah before his wife returned to Britain for several weeks.It has been reported that Felix-Browne met bin Laden while she was undergoing treatment for multiple sclerosis. They met on a horseback ride at the Giza pyramids in Egypt. She is his second wife and 24 years older than he is, with five grandchildren.  She was aware when she married bin Laden that he had been married and divorced, with a two-year-old son.After their wedding, Al-Sabah described the stress of bin Laden\'s family background: "Omar is wary of everyone. He is constantly watching people who he feels might be following him. Not without reason he is fearful of cameras. He is the son of Osama. But when we are together he forgets his life." The couple announced their divorce in September 2007, which was said to be in response to threats to their "lives and liberty" from two unspecified sources known to them in Saudi Arabia. At the time, Al-Sabah said she did not regard herself as divorced and that as the divorce was done under duress did not have legal standing under Sharia law. After two weeks, they decided not to part.\nIn January 2008, bin Laden applied for a British spousal immigration visa which would have permitted him to reside indefinitely at his wife\'s home in Moulton, Cheshire, a process which required him to provide original documentation of his divorce from his first wife. The couple stated their desire to have a child using a surrogate mother. One report stated the visa application was denied because bin Laden failed to provide his father\'s permanent address.  However, a later report by The Times of bin Laden\'s appeal stated that the visa had been denied by an entry clearance officer at the UK embassy in Cairo because bin Laden\'s entry would cause "considerable public concern." The officer was quoted "I note that statements made during recent media interviews indicate evidence of continuing loyalty to your father, and your presence in the UK could, therefore, cause considerable public concern." This written statement was shown to The Associated Press by the couple\'s legal firm, but Britain\'s Home Office declined to comment to the press on an individual case. In April 2008, bin Laden and Al-Sabah said they planned to appeal the ruling, calling it "unjust and arbitrary", stating that Al-Sabah requires medical attention in Britain and that her appeal to live with him in Saudi Arabia could take years to process. As of April 2008, bin Laden has a house in Cairo.In April 2010, bin Laden was denied a visa to promote his book Osama bin Laden: A Family Portrait in France and elsewhere in Europe.\nSpecifically, the countries of the Schengen zone, a block of 25 nations across Europe including Germany, France and Spain, rejected his request for a visa.In July 2010, Felix-Browne told the media that bin Laden suffers from bipolar disorder and that he was in a Qatari mental institution after hearing voices. Felix-Browne told the media that when bin Laden returned to the UK, Felix-Browne told him she wanted a divorce. As of 2015, they have been married for 9 years and are living in an undisclosed country. All previous talk of divorce was publicized under duress and threats to their lives and their families\' lives.\n\n\n=== North African horse race ===\n\nIn January 2008, an Associated Press interview in Cairo featured bin Laden with cornrows and a black leather biker jacket promoting a 4,800-kilometre (3,000 mi) horse race for peace across North Africa.Bin Laden described the race as an equine counterpart to the canceled 2008 Paris-Dakar car rally, saying, "I heard the rally was stopped because of al-Qaida.  I don\'t think they are going to stop me." The race was canceled after the killings of four French tourists near Aleg, Mauritania on Christmas Eve 2007. Following the murders race organizers received threats directly from heavily armed and organized groups linked to al-Qaeda, which led them to cancel the race on January 4, 2008, and soon after to plan the 2009 event for South America. Police in Guinea-Bissau said that two of five men arrested for the crime on January 11, 2008, admitted their involvement with al-Qaeda.\n\n\n=== Relationship to his father and al-Qaeda ===\nBin Laden said that his father felt that he was just trying to defend the Islamic world, and that his father was not a terrorist "because history tells you he\'s not". In an interview with ABC News, he said, "My father is a very kind man. And he is very sorry when he did something like 11th September." Osama bin Laden ordered the attacks "Because he believes if he put two buildings down, maybe some people, little will die, but millions other will (be) save(d). He believed that. ... I believe he did wrong". In a January 21, 2008, CNN interview, he said, "I try and say to my father: \'Try to find another way to help or find your goal. This bomb, these weapons, it\'s not good to use them on anybody". Regarding the September 11 attacks, he said, "I don\'t think 9/11 was right personally, but it happened. I don\'t think ... [the war] in Vietnam was right. I don\'t think what\'s going on in Palestine is right. I don\'t think what\'s going on in Iraq is right. If we make what is right and not right, we will make a very big list."Bin Laden stated that he had not been in contact with his father since leaving Afghanistan in 2000. He said, "The last time I saw my father was in 2000, 2001. I was in Saudi Arabia and felt a terrible sorrow for all the victims [of the September 11 attacks]", "My father has a kind heart", and "I do not believe my father is dead, otherwise I would have known it; the world would have known it." When asked whether he would tell the Americans if he found out where his father was living, he said with a smile, "Actually, I would hide him. Because he is my father."According to Time, bin Laden has stated a desire to become an "ambassador of peace" between Muslims and the West.  Bin Laden said that his father offered a truce to Europe in a 2004 videotape and a conditional truce with the United States in a 2006 videotape. "My father is asking for a truce but I don\'t think there is any government (that) respects him. At the same time they do not respect him, why everywhere in the world, they want to fight him? There is a contradiction." The truces offered in these videos of Osama bin Laden were promptly rejected at the time.After arriving in Rome from Switzerland amid heavy security on February 2, 2008, bin Laden said in a television interview that night "I would very much like to meet the Pope in Saint Peter\'s, but I have been told that it is not easy."\n\n\n=== Asylum petitions ===\nOn November 3, 2008, Spain\'s Interior Ministry, upon recommendation by the United Nations High Commissioner for Refugees denied, for "insufficient evidence of danger or threat to [his] life", bin Laden\'s political asylum petition, after he was refused a UK visa. Bin Laden had 24 hours to appeal, after he made his claim at Madrid\'s Barajas International Airport upon a stopover on a flight from Cairo, Egypt to Casablanca, Morocco.Bin Laden and his wife arrived in Doha, Qatar (where, as a Saudi citizen with a Saudi passport, he would have right of entry), on November 9, 2008, after deportation by Egypt per its denial of their entry.\nBin Laden filed another British visa petition in 2008.\n\n\n=== Book ===\nBin Laden and his mother Najwa bin Laden published a book authored in late October 2009, titled Growing Up bin Laden. According to media coverage, the book details that "the kids grew up in Saudi Arabia, Sudan, and Afghanistan without laughter or toys, were routinely beaten, and lost their pets to painful death from poison gas experiments by their father\'s fighters." It states that Osama bin Laden tried to persuade his son to volunteer for suicide missions and exposed him to dangerous conditions visiting training camps in Afghanistan and sending him to the front lines of the Afghan civil war. The book describes the family living in Jeddah without air conditioning or refrigeration, treating asthma with honeycombs and onions, and eventually moving to stone huts in Tora Bora without electricity or running water in 1996.\nSubsequent correspondence with the Associated Press indicated that 25 bin Laden family members had moved to Iran, following U.S. involvement in Afghanistan.\n\n\n=== Death of his father ===\n\nBin Laden published a complaint on May 10, 2011, that the burial at sea of his father deprived the family of a proper burial. He made several other claims regarding the mission that killed his father, such as stating that no one living at the compound was armed; he also requested that the UN and other international groups investigate the killing of Osama bin Laden as a criminal matter. His requests were ignored by the U.S. and no actions based on them have been taken so far.\n\n\n== References ==\n\n\n== External links ==\nOmar Bin Laden Interview - Published 19 November 2009', "This is a list of central banks. Countries that are only partially recognized internationally are marked with an asterisk (*).\n\n\n== Disappeared central banking jurisdictions ==\n City of Amsterdam – Bank of Amsterdam (1609-1791)\n City of Barcelona – Taula de canvi de Barcelona (1401-1714)\n British East Africa – East African Currency Board (1919-1966)\n Independent State of Croatia – Croatian State Bank (Hrvatska Državna Banka, 1941-1945)\n Czechoslovakia – National Bank of Czechoslovakia (1926–1939 and 1945-1950) and State Bank of Czechoslovakia (1950–1992)\n Free City of Frankfurt – Frankfurter Bank (1854-1875)\n Republic of Genoa – Bank of Saint George (1407-1805)\n German Democratic Republic – Deutsche Notenbank (1948-1968) and Staatsbank der DDR (1968-1990)\n Free and Hanseatic City of Hamburg – Hamburger Bank (1619-1875)\n Korea under Japanese and American rule – Bank of Korea (1909–1950)\n Manchukuo – Central Bank of Manchou (1932-1945)\n Kingdom of Prussia – Königliche Hauptbank (1765-1846) and Bank of Prussia (1847-1875)\n Kingdom of Sardinia – Banca Nazionale negli Stati Sardi (1849-1861), itself formed through the merger of Banca di Genova (1846-1849) and Banca di Torino (1847-1849)\n Kingdom of the Two Sicilies – Banco di Napoli, under different names from 1463 to final end of central banking role in 1926\n Grand Duchy of Tuscany – Banca di Firenze (1816-1893), renamed National Tuscan Bank from 1857\n Soviet Union – People's Bank (1917-1922) and Gosbank (1922-1991)\n Republic of Venice – Banco del Giro (1524-1806)\n Yugoslavia – the National Bank of Serbia, successively named National Bank of the Kingdom of Serbs, Croats and Slovenes (1920-1929), National Bank of the Kingdom of Yugoslavia (1929-1946), and National Bank of Yugoslavia (1946-2003)\n\n\n== See also ==\nCentral banks and currencies of Africa\nCentral banks and currencies of the Caribbean\nCentral banks and currencies of Central America and South America\nCentral banks and currencies of Europe\nList of currencies\nInternational Monetary Fund –  Lender of last resort to countries short of liquidity\nBank for International Settlements – an international organisation which fosters international monetary and financial cooperation and serves as a bank for central banks.\n\n\n== Notes ==\n\n\n== External links ==\nCentralbanksguide.com: Central Banks of the World website\nBIS.org:  Bank for International Settlements−BIS.org: List of Central banks of the World — with links to websites.", 'The Ten Commandments (Hebrew: עֲשֶׂרֶת הַדִּבְּרוֹת, Aseret ha\'Dibrot), also known as the Decalogue, are a set of biblical principles relating to ethics and worship that play a fundamental role in Judaism and Christianity. The text of the Ten Commandments appears twice in the Hebrew Bible: at Exodus 20:2–17 and Deuteronomy 5:6–21.\nScholars disagree about when the Ten Commandments were written and by whom, with some modern scholars suggesting that they were likely modeled on Hittite and Mesopotamian laws and treaties. According to the book of Exodus in the Torah, the Ten Commandments were revealed to Moses at Mount Sinai and inscribed by the finger of God on two tablets of stone kept in the Ark of the Covenant.\n\n\n== Terminology ==\n\nIn Biblical Hebrew, the Ten Commandments, called עשרת הדיברות\u200e (transliterated aseret ha-dibrot), are mentioned at Exodus 34:28, Deuteronomy 4:13 and Deuteronomy 10:4. In all sources, the terms are translatable as "the ten words", "the ten sayings", or "the ten matters".In the Septuagint (or LXX), the  "ten words" was translated as "Decalogue", which is derived from Greek δεκάλογος, dekalogos, the latter meaning and referring to the Greek translation (in accusative) δέκα λόγους, deka logous. This term is also sometimes used in English, in addition to Ten Commandments. The Tyndale and Coverdale English biblical translations used "nine verses". The Geneva Bible used "ten commandments", which was followed by the Bishops\' Bible and the Authorized Version (the "King James" version) as "ten commandments". Most major English versions use the word "commandments".The stone tablets, as opposed to the ten commandments inscribed on them, are called לוחות הברית\u200e, Lukhot HaBrit, meaning "the tablets of the covenant".\n\n\n== Biblical narrative ==\n\nThe biblical narrative of the revelation at Sinai begins in Exodus 19 after the arrival of the children of Israel at Mount Sinai (also called Horeb). On the morning of the third day of their encampment, "there were thunders and lightnings, and a thick cloud upon the mount, and the voice of the trumpet exceeding loud", and the people assembled at the base of the mount. After "the LORD came down upon mount Sinai", Moses went up briefly and returned to prepare the people, and then in Exodus 20 "God spoke" to all the people the words of the covenant, that is, the "ten commandments" as it is written.  Modern biblical scholarship differs as to whether Exodus 19–20 describes the people of Israel as having directly heard all or some of the decalogue, or whether the laws are only passed to them through Moses.The people were afraid to hear more and moved "afar off", and Moses responded with "Fear not." Nevertheless, he drew near the "thick darkness" where "the presence of the Lord" was to hear the additional statutes and "judgments", all which he "wrote" in the "book of the covenant" which he read to the people the next morning, and they agreed to be obedient and do all that the LORD had said. Moses escorted a select group consisting of Aaron, Nadab and Abihu, and "seventy of the elders of Israel" to a location on the mount where they worshipped "afar off" and they "saw the God of Israel" above a "paved work" like clear sapphire stone.\nAnd the LORD said unto Moses, Come up to me into the mount, and be there: and I will give thee tablets of stone, and a law, and commandments which I have written; that thou mayest teach them. 13 And Moses rose up, and his minister Joshua: and Moses went up into the mount of God.\nThe mount was covered by the cloud for six days, and on the seventh day Moses went into the midst of the cloud and was "in the mount forty days and forty nights." And Moses said, "the LORD delivered unto me two tablets of stone written with the finger of God; and on them was written according to all the words, which the LORD spake with you in the mount out of the midst of the fire in the day of the assembly." Before the full forty days expired, the children of Israel collectively decided that something had happened to Moses, and compelled Aaron to fashion a golden calf, and he "built an altar before it" and the people "worshipped" the calf.\n\nAfter the full forty days, Moses and Joshua came down from the mountain with the tablets of stone: "And it came to pass, as soon as he came nigh unto the camp, that he saw the calf, and the dancing: and Moses\' anger waxed hot, and he cast the tablets out of his hands, and brake them beneath the mount." After the events in chapters 32 and 33, the LORD told Moses, "Hew thee two tablets of stone like unto the first: and I will write upon these tablets the words that were in the first tablets, which thou brakest." "And he wrote on the tablets, according to the first writing, the ten commandments, which the LORD spake unto you in the mount out of the midst of the fire in the day of the assembly: and the LORD gave them unto me." These tablets were later placed in the ark of the covenant.\n\n\n== Numbering ==\nAlthough both the Masoretic Text and the Dead Sea Scrolls show the passages of Exodus 20 and Deuteronomy 5 divided into ten specific commandments with spaces between them, many Modern English Bible translations give the appearance of more than ten imperative statements in each passage.\nDifferent religious traditions divide the seventeen verses of Exodus 20:1–17 and their parallels in Deuteronomy 5:4–21 into ten commandments in different ways, shown in the table below. Some suggest that the number ten is a choice to aid memorization rather than a matter of theology.\nAll scripture quotes above are from the King James Version unless otherwise stated.Traditions:\n\nT: Jewish Talmud, makes the "prologue" the first "saying" or "matter" and combines the prohibition on worshiping deities other than Yahweh with the prohibition on idolatry.\nR: Reformed Christians follow John Calvin\'s Institutes of the Christian Religion, which follows the Septuagint; this system is also used in the Anglican Book of Common Prayer.\nLXX: Septuagint, generally followed by Orthodox Christians.\nP: Philo, has an extensive homily on why the order is so important, with the prohibition on adultery "the greatest of the commands dealing with persons", followed by the prohibitions against stealing and then killing last.\nL: Lutherans follow Luther\'s Large Catechism, which follows Augustine but subordinates the prohibition of images to the sovereignty of God in the First Commandment and uses the word order of Exodus 20:17 rather than Deuteronomy 5:21 for the ninth and tenth commandments.\nS: Samaritan Pentateuch, with an additional commandment about Mount Gerizim as 10th.\nA: Augustine follows the Talmud in combining verses 3–6, but omits the prologue as a commandment and divides the prohibition on coveting in two and following the word order of Deuteronomy 5:21 rather than Exodus 20:17.\nC: Catechism of the Catholic Church, largely follows Augustine. Combines the Exodus language prohibiting images of God with the command to have no other gods but the Lord, as the first commandment.  Changes "the sabbath" into "the lord\'s day".  Divides Exodus 20:17, prohibiting covetousness, into two commandments.\n\n\n== Religious interpretations ==\nThe Ten Commandments concern matters of fundamental importance in Judaism and Christianity: the greatest obligation (to worship only God), the greatest injury to a person (murder), the greatest injury to family bonds (adultery), the greatest injury to commerce and law (bearing false witness), the greatest inter-generational obligation (honour to parents), the greatest obligation to community (truthfulness), the greatest injury to movable property (theft).The Ten Commandments are written with room for varying interpretation, reflecting their role as a summary of fundamental principles. They are not as explicit or as detailed as rules or as many other biblical laws and commandments, because they provide guiding principles that apply universally, across changing circumstances. They do not specify punishments for their violation. Their precise import must be worked out in each separate situation.The Bible indicates the special status of the Ten Commandments among all other Torah laws in several ways:\n\nThey have a uniquely terse style.\nOf all the biblical laws and commandments, the Ten Commandments alone are said to have been "written with the finger of God" (Exodus 31:18).\nThe stone tablets were placed in the Ark of the Covenant (Exodus 25:21, Deuteronomy 10:2,5).\n\n\n=== Judaism ===\n\nThe Ten Commandments form the basis of Jewish law, stating God\'s universal and timeless standard of right and wrong – unlike the rest of the 613 commandments in the Torah, which include, for example, various duties and ceremonies such as the kashrut dietary laws, and the rituals to be performed by priests in the Holy Temple. Jewish tradition considers the Ten Commandments the theological basis for the rest of the commandments. Philo, in his four-book work The Special Laws, treated the Ten Commandments as headings under which he discussed other related commandments. Similarly, in The Decalogue he stated that "under [the "commandment… against adulterers"] many other commands are conveyed by implication, such as that against seducers, that against practisers of unnatural crimes, that against all who live in debauchery, that against all men who indulge in illicit and incontinent connections." Others, such as Rabbi Saadia Gaon, have also made groupings of the commandments according to their links with the Ten Commandments.According to Conservative Rabbi Louis Ginzberg, Ten Commandments are virtually entwined, in that the breaking of one leads to the breaking of another. Echoing an earlier rabbinic comment found in the commentary of Rashi to the Songs of Songs (4:5) Ginzberg explained—there is also a great bond of union between the first five commandments and the last five. The first commandment: "I am the Lord, thy God," corresponds to the sixth: "Thou shalt not kill," for the murderer slays the image of God. The second: "Thou shalt have no strange gods before me," corresponds to the seventh: "Thou shalt not commit adultery," for conjugal faithlessness is as grave a sin as idolatry, which is faithlessness to God. The third commandment: "Thou shalt not take the name of the Lord in vain," corresponds to the eighth: "Thou shalt not steal," for stealing results in a false oath in God\'s name. The fourth: "Remember the Sabbath day, to keep it holy," corresponds to the ninth: "Thou shalt not bear false witness against thy neighbor," for he who bears false witness against his neighbor commits as grave a sin as if he had borne false witness against God, saying that He had not created the world in six days and rested on the seventh day (the holy Sabbath). The fifth commandment: "Honor thy father and thy mother," corresponds to the tenth: "Covet not thy neighbor\'s wife," for one who indulges this lust produces children who will not honor their true father, but will consider a stranger their father.The traditional Rabbinical Jewish belief is that the observance of these commandments and the other mitzvot are required solely of the Jewish people and that the laws incumbent on humanity in general are outlined in the seven Noahide laws, several of which overlap with the Ten Commandments. In the era of the Sanhedrin transgressing any one of six of the Ten Commandments theoretically carried the death penalty, the exceptions being the First Commandment, honouring your father and mother, saying God\'s name in vain, and coveting, though this was rarely enforced due to a large number of stringent evidentiary requirements imposed by the oral law.\n\n\n==== Two tablets ====\n\nThe arrangement of the commandments on the two tablets is interpreted in different ways in the classical Jewish tradition. Rabbi Hanina ben Gamaliel says that each tablet contained five commandments, "but the Sages say ten on one tablet and ten on the other", that is, that the tablets were duplicates. This can be compared to diplomatic treaties of the ancient Near East, in which a copy was made for each party.According to the Talmud, the compendium of traditional Rabbinic Jewish law, tradition, and interpretation, one interpretation of the biblical verse "the tablets were written on both their sides", is that the carving went through the full thickness of the tablets, yet was miraculously legible from both sides.\n\n\n==== Use in Jewish ritual ====\n\nThe Mishna records that during the period of the Second Temple, the Ten Commandments were recited daily, before the reading of the Shema Yisrael (as preserved, for example, in the Nash Papyrus, a Hebrew manuscript fragment from 150 to 100 BCE found in Egypt, containing a version of the ten commandments and the beginning of the Shema); but that this practice was abolished in the synagogues so as not to give ammunition to heretics who claimed that they were the only important part of Jewish law, or to dispel a claim by early Christians that only the Ten Commandments were handed down at Mount Sinai rather than the whole Torah.